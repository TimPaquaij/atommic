{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the [AHEAD](https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/IHZGQM) dataset.\n",
    "\n",
    "Note: Please be patient at times when running the code. Depending on your machine, it can take ~1 hour to run everything on this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data in the AHEAD dataset are scanned using the MP2RAGEME sequence for T1, T2* and Quantitative Susceptibility Mapping in one sequence at 7 Tesla. Data are motion-corrected using Fat navigators (FatNavs), and defaced in image-domain.\n",
    "\n",
    "### Use the link to download the dataset. The dataset is in the [ISMRMRD](https://ismrmrd.github.io/) format. We will use the [ismrmrd-python-tools](https://github.com/ismrmrd/ismrmrd-python-tools) to read the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:51:53.574330Z",
     "end_time": "2023-11-15T23:51:55.895385Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install ismrmrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:51:55.894679Z",
     "end_time": "2023-11-15T23:51:56.039683Z"
    }
   },
   "outputs": [],
   "source": [
    "import ismrmrd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this example we will use the data of subject 001, the 2nd inversion and the 1st echo time. Please change the `dataset_path` accordingly. The filename is `mp2rageme_001_inv2_te1.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:51:59.712068Z",
     "end_time": "2023-11-15T23:51:59.760938Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = input(\"Please enter the (downloaded) data path: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:52:00.996454Z",
     "end_time": "2023-11-15T23:52:01.076025Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = f\"{dataset_path}/mp2rageme_001_inv2_te1.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use the `ismrmrd.Dataset` class to read the data.\n",
    "\n",
    "- The `dataset` argument is the path to the dataset.\n",
    "- The `create_if_needed` argument is set to `False` because we do not want to create a new dataset if it does not exist.\n",
    "- The `number_of_acquisitions` method returns the number of acquisitions in the dataset. We will use this to loop over all acquisitions.\n",
    "- We will use the `read_acquisition` method to read the acquisitions.\n",
    "- The `getHead` method returns the header of the acquisition.\n",
    "- The `isFlagSet` method returns `True` if the flag is set. We will use this to find the noise scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:52:03.058042Z",
     "end_time": "2023-11-15T23:52:03.076965Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ismrmrd.Dataset(filename, 'dataset', create_if_needed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:52:03.682418Z",
     "end_time": "2023-11-15T23:52:03.741259Z"
    }
   },
   "outputs": [],
   "source": [
    "number_of_acquisitions = dataset.number_of_acquisitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find the first scan that is not a noise scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:52:05.341403Z",
     "end_time": "2023-11-15T23:56:32.355027Z"
    }
   },
   "outputs": [],
   "source": [
    "# find the first no noise scan\n",
    "first_scan = 0\n",
    "for i in tqdm(range(number_of_acquisitions)):\n",
    "    head = dataset.read_acquisition(i).getHead()\n",
    "    if head.isFlagSet(ismrmrd.ACQ_IS_NOISE_MEASUREMENT):\n",
    "        first_scan = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read the data into a list of acquisitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:56:32.336053Z",
     "end_time": "2023-11-15T23:59:49.797476Z"
    }
   },
   "outputs": [],
   "source": [
    "meas = []\n",
    "for i in tqdm(range(first_scan, number_of_acquisitions)):\n",
    "    acq = dataset.read_acquisition(i)\n",
    "    meas.append(acq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read the header of the dataset.\n",
    "\n",
    "- The `xsd.CreateFromDocument` method deserializes the header.\n",
    "- The `read_xml_header` method returns the header of the dataset.\n",
    "- The `hdr.acquisitionSystemInformation` returns the acquisition system information.\n",
    "- The `hdr.experimentalConditions` returns the experimental conditions.\n",
    "- The `hdr.sequenceParameters` returns the sequence parameters.\n",
    "- The `hdr.userParameters.userParameterLong` returns the user parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.772979Z",
     "end_time": "2023-11-15T23:59:49.799033Z"
    }
   },
   "outputs": [],
   "source": [
    "hdr = ismrmrd.xsd.CreateFromDocument(dataset.read_xml_header())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.773069Z",
     "end_time": "2023-11-15T23:59:49.799501Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Acquisition system information: {hdr.acquisitionSystemInformation} \\n\"\n",
    "    f\"Experimental conditions: {hdr.experimentalConditions} \\n\"\n",
    "    f\"Sequence parameters: {hdr.sequenceParameters} \\n\"\n",
    "    f\"User parameters: {hdr.userParameters.userParameterLong} \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read the encoding information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.773140Z",
     "end_time": "2023-11-15T23:59:49.813485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matrix size\n",
    "enc = hdr.encoding[0]\n",
    "enc_Nx = enc.encodedSpace.matrixSize.x\n",
    "enc_Ny = enc.encodedSpace.matrixSize.y\n",
    "enc_Nz = enc.encodedSpace.matrixSize.z\n",
    "rec_Nx = enc.reconSpace.matrixSize.x\n",
    "rec_Ny = enc.reconSpace.matrixSize.y\n",
    "rec_Nz = enc.reconSpace.matrixSize.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.813200Z",
     "end_time": "2023-11-15T23:59:49.813792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Field of view\n",
    "enc_FOVx = enc.encodedSpace.fieldOfView_mm.x\n",
    "enc_FOVy = enc.encodedSpace.fieldOfView_mm.y\n",
    "enc_FOVz = enc.encodedSpace.fieldOfView_mm.z\n",
    "rec_FOVx = enc.reconSpace.fieldOfView_mm.x\n",
    "rec_FOVy = enc.reconSpace.fieldOfView_mm.y\n",
    "rec_FOVz = enc.reconSpace.fieldOfView_mm.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.813284Z",
     "end_time": "2023-11-15T23:59:49.813909Z"
    }
   },
   "outputs": [],
   "source": [
    "nCoils = hdr.acquisitionSystemInformation.receiverChannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.813333Z",
     "end_time": "2023-11-15T23:59:49.814148Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Matrix size: {enc_Nx} x {enc_Ny} x {enc_Nz} \\n\"\n",
    "    f\"Field of view: {enc_FOVx} x {enc_FOVy} x {enc_FOVz} \\n\"\n",
    "    f\"Number of coils: {nCoils} \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read the encoding limits. We will use these to select the appropriate measurements from the data.\n",
    "\n",
    "- The `encodingLimits.slice.maximum` returns the maximum slice index.\n",
    "- The `encodingLimits.repetition.maximum` returns the maximum repetition index.\n",
    "- The `encodingLimits.contrast.maximum` returns the maximum contrast index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.813397Z",
     "end_time": "2023-11-15T23:59:49.814257Z"
    }
   },
   "outputs": [],
   "source": [
    "nslices = enc.encodingLimits.slice.maximum + 1 if enc.encodingLimits.slice is not None else 1\n",
    "nreps = enc.encodingLimits.repetition.maximum + 1 if enc.encodingLimits.repetition is not None else 1\n",
    "ncontrasts = enc.encodingLimits.contrast.maximum + 1 if enc.encodingLimits.contrast is not None else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.813476Z",
     "end_time": "2023-11-15T23:59:49.814493Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of slices: {nslices} \\n\"\n",
    "    f\"Number of repetitions: {nreps} \\n\"\n",
    "    f\"Number of contrasts: {ncontrasts} \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read the data into a k-space (numpy) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.813711Z",
     "end_time": "2023-11-15T23:59:49.814598Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.813775Z",
     "end_time": "2023-11-15T23:59:49.814688Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize k-space array\n",
    "Kread = np.zeros((enc_Nx, enc_Ny, enc_Nz, nCoils), dtype=np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.813842Z",
     "end_time": "2023-11-15T23:59:50.070591Z"
    }
   },
   "outputs": [],
   "source": [
    "Kread.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:49.852697Z",
     "end_time": "2023-11-15T23:59:57.688053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select the appropriate measurements from the data\n",
    "for acq in tqdm(meas):\n",
    "    head = acq.getHead()\n",
    "    if head.idx.contrast == ncontrasts - 1 and head.idx.repetition == nreps - 1 and head.idx.slice == nslices - 1:\n",
    "        head = acq.getHead()\n",
    "        ky = head.idx.kspace_encode_step_1\n",
    "        kz = head.idx.kspace_encode_step_2\n",
    "        Kread[:, ky, kz, :] = np.transpose(acq.data, (1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:57.658905Z",
     "end_time": "2023-11-15T23:59:57.689232Z"
    }
   },
   "outputs": [],
   "source": [
    "Kread.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot the k-space data.\n",
    "\n",
    "Note: For visualization purposes and ease of example, we will use only one slice and one coil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:57.658996Z",
     "end_time": "2023-11-15T23:59:57.689374Z"
    }
   },
   "outputs": [],
   "source": [
    "slice_idx = 100\n",
    "coil_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-15T23:59:57.659058Z",
     "end_time": "2023-11-15T23:59:57.943054Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:00:22.164525Z",
     "end_time": "2023-11-16T00:00:22.397618Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.log(np.abs(Kread[slice_idx, :, :, coil_idx]) + 1e-9), cmap=\"gray\")\n",
    "plt.title(\"k-space\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's perform the inverse Fourier transform. We will use the `fftshift` and `ifftshift` methods to center the k-space data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:00:27.665784Z",
     "end_time": "2023-11-16T00:02:03.408811Z"
    }
   },
   "outputs": [],
   "source": [
    "# orthogonal/centered IFFT\n",
    "Imread = np.fft.fftshift(np.fft.ifftn(np.fft.ifftshift(Kread, axes=(0, 1, 2)), axes=(0, 1, 2)), axes=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:02:03.408108Z",
     "end_time": "2023-11-16T00:02:23.707793Z"
    }
   },
   "outputs": [],
   "source": [
    "Imread = Imread / np.max(np.abs(Imread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:02:23.707761Z",
     "end_time": "2023-11-16T00:02:24.497034Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.angle(Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Phase\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.real(Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Real part\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.imag(Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read the coil sensitivities. The coil sensitivities are stored in a separate file and NOT in raw format. We will use the `h5py` package to read the data. The coil sensitivities are stored in the `0real` and `1imag` datasets. We will read the data into a numpy array and then transpose the array to match the dimensions of the k-space data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:02:31.418570Z",
     "end_time": "2023-11-16T00:02:31.619989Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities_filename = f\"{dataset_path}/coilsens_001.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:02:31.558783Z",
     "end_time": "2023-11-16T00:02:31.688849Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:02:31.973663Z",
     "end_time": "2023-11-16T00:02:32.028619Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities = h5py.File(coil_sensitivities_filename, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:02:32.385297Z",
     "end_time": "2023-11-16T00:02:32.437153Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:02:32.724851Z",
     "end_time": "2023-11-16T00:03:10.040915Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities_real = np.array(coil_sensitivities[\"0real\"])\n",
    "coil_sensitivities_imag = np.array(coil_sensitivities[\"1imag\"])\n",
    "coil_sensitivities = coil_sensitivities_real + 1j * coil_sensitivities_imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:10.041485Z",
     "end_time": "2023-11-16T00:03:10.042748Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:10.041733Z",
     "end_time": "2023-11-16T00:03:10.042975Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities = np.transpose(coil_sensitivities, (3, 2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:10.041856Z",
     "end_time": "2023-11-16T00:03:10.043261Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:10.041977Z",
     "end_time": "2023-11-16T00:03:22.229988Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities = coil_sensitivities / np.max(np.abs(coil_sensitivities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:22.050897Z",
     "end_time": "2023-11-16T00:03:22.652297Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.angle(coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Phase\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.real(coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Real part\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.imag(coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's calculate the target image. We will use the SENSE reconstruction method to calculate the target image. The target image is the sum of the product of the k-space data and the complex conjugate of the coil sensitivities. We will then normalize the target image by the maximum value of the absolute value of the target image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:22.652115Z",
     "end_time": "2023-11-16T00:03:27.415849Z"
    }
   },
   "outputs": [],
   "source": [
    "target = np.sum(Imread[slice_idx] * np.conj(coil_sensitivities[slice_idx]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:27.455044Z",
     "end_time": "2023-11-16T00:03:27.493673Z"
    }
   },
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:27.455305Z",
     "end_time": "2023-11-16T00:03:27.493963Z"
    }
   },
   "outputs": [],
   "source": [
    "target = target / np.max(np.abs(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:27.455433Z",
     "end_time": "2023-11-16T00:03:28.079655Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(target), cmap=\"gray\")\n",
    "plt.title(\"Magnitude\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.angle(target), cmap=\"gray\")\n",
    "plt.title(\"Phase\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.real(target), cmap=\"gray\")\n",
    "plt.title(\"Real part\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.imag(target), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have now verified that the data look correct and we have find the correct transformations to preprocess our data. Let's now get another plane, the axial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:28.078673Z",
     "end_time": "2023-11-16T00:03:28.080055Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the axial plane\n",
    "axial_Kread = np.transpose(Kread, (2, 0, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:03:28.080526Z",
     "end_time": "2023-11-16T00:05:31.234454Z"
    }
   },
   "outputs": [],
   "source": [
    "axial_Imread = np.fft.fftshift(np.fft.ifftn(np.fft.ifftshift(axial_Kread, axes=(0, 1, 2)), axes=(0, 1, 2)), axes=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:05:31.233974Z",
     "end_time": "2023-11-16T00:05:31.832590Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(axial_Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.angle(axial_Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Phase\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.real(axial_Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Real part\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.imag(axial_Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's transform our data to get the proper orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:05:31.832492Z",
     "end_time": "2023-11-16T00:05:31.833131Z"
    }
   },
   "outputs": [],
   "source": [
    "axial_Imread = np.rot90(axial_Imread, k=1, axes=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:05:31.832945Z",
     "end_time": "2023-11-16T00:05:32.657741Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(axial_Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.angle(axial_Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Phase\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.real(axial_Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Real part\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.imag(axial_Imread[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:05:32.657077Z",
     "end_time": "2023-11-16T00:09:10.528601Z"
    }
   },
   "outputs": [],
   "source": [
    "# get axial coil sensitivities\n",
    "axial_coil_sensitivities = np.fft.fftn(coil_sensitivities, axes=(0, 1, 2))\n",
    "axial_coil_sensitivities = np.transpose(axial_coil_sensitivities, (2, 0, 1, 3))\n",
    "axial_coil_sensitivities = np.fft.ifftn(axial_coil_sensitivities, axes=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:09:10.527968Z",
     "end_time": "2023-11-16T00:09:11.165512Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(axial_coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.angle(axial_coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Phase\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.real(axial_coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Real part\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.imag(axial_coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's transform our data to get the proper orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:09:11.164772Z",
     "end_time": "2023-11-16T00:09:11.165871Z"
    }
   },
   "outputs": [],
   "source": [
    "axial_coil_sensitivities = np.rot90(axial_coil_sensitivities, k=1, axes=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T00:09:11.164997Z",
     "end_time": "2023-11-16T00:09:12.520144Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(axial_coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.angle(axial_coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Phase\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.real(axial_coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Real part\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.imag(axial_coil_sensitivities[slice_idx, :, :, coil_idx]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:34:57.297356Z",
     "end_time": "2023-11-16T02:35:02.562369Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the axial target\n",
    "axial_target = np.sum(axial_Imread[slice_idx] * np.conj(axial_coil_sensitivities[slice_idx]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:35:02.546013Z",
     "end_time": "2023-11-16T02:35:03.220159Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(axial_target), cmap=\"gray\")\n",
    "plt.title(\"Magnitude\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(np.angle(axial_target), cmap=\"gray\")\n",
    "plt.title(\"Phase\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.real(axial_target), cmap=\"gray\")\n",
    "plt.title(\"Real part\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.imag(axial_target), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We verified that we can get the axial images properly as well. Let's get going and estimate parameter maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we need to calculate the brain mask. We will use the axial images for this. We will use the Otsu thresholding method to estimate the brain mask. We will then dilate the brain mask to get a better estimate of the brain mask. We will then get the convex hull of the brain mask to get a better estimate of the brain mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:37:25.305768Z",
     "end_time": "2023-11-16T02:37:25.420686Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import binary_dilation, binary_erosion, binary_fill_holes\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate otsu's threshold\n",
    "threshold = threshold_otsu(np.abs(axial_target))\n",
    "# get the connected components and apply threshold\n",
    "axial_target_cc = measure.label(np.abs(axial_target) > threshold * 2) + measure.label(np.abs(axial_target) > threshold)\n",
    "# Get mask\n",
    "skull_mask = np.where(axial_target_cc != 0, 1, 0)\n",
    "# get the convex hull\n",
    "brain_mask = convex_hull_image(skull_mask) * (1 - skull_mask)\n",
    "# perform binary erosion to remove skull\n",
    "brain_mask = binary_erosion(brain_mask, iterations=4)\n",
    "# get the convex hull of the brain mask\n",
    "brain_mask = convex_hull_image(brain_mask)\n",
    "# threshold the brain mask\n",
    "brain_mask = np.where(np.abs(axial_target) * brain_mask > threshold / 2, 1, 0)\n",
    "# perform binary erosion to remove skull\n",
    "brain_mask = binary_erosion(brain_mask, iterations=4)\n",
    "# perform binary dilation to get the brain mask\n",
    "brain_mask = binary_dilation(brain_mask, iterations=4)\n",
    "# fill holes in the brain mask\n",
    "brain_mask = binary_fill_holes(brain_mask)\n",
    "# get the convex hull of the brain mask\n",
    "brain_mask = convex_hull_image(brain_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-16T02:37:26.428468Z",
     "end_time": "2023-11-16T02:37:26.523826Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "brain_mask.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-16T02:37:28.073125Z",
     "end_time": "2023-11-16T02:37:28.161047Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:37:29.216511Z",
     "end_time": "2023-11-16T02:37:29.848972Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(np.abs(axial_target), cmap=\"gray\")\n",
    "plt.title(\"Axial Target\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(brain_mask, cmap=\"gray\")\n",
    "plt.title(\"Brain Mask\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(np.abs(axial_target) * brain_mask, cmap=\"gray\")\n",
    "plt.title(\"Axial Target * Brain Mask\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(np.abs(axial_target) * (1 - brain_mask), cmap=\"gray\")\n",
    "plt.title(\"Axial Target * Head Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we will estimate quantitative maps. We will estimate R2*, S0, B0, and phi maps. But first we need to apply the brain mask to the images and unwrap the phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:43:54.017246Z",
     "end_time": "2023-11-16T01:44:00.599866Z"
    }
   },
   "outputs": [],
   "source": [
    "coilimgs = axial_Imread[slice_idx] * np.repeat(brain_mask[..., np.newaxis], axial_Imread.shape[-1], axis=-1)\n",
    "sense = axial_coil_sensitivities[slice_idx] * np.repeat(brain_mask[..., np.newaxis], axial_coil_sensitivities.shape[-1], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:44:00.601095Z",
     "end_time": "2023-11-16T01:44:00.618656Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.restoration import unwrap_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:44:00.619410Z",
     "end_time": "2023-11-16T01:44:00.706299Z"
    }
   },
   "outputs": [],
   "source": [
    "phases = np.angle(np.sum(coilimgs * sense.conj(), -1))\n",
    "phase_unwrapped = unwrap_phase(np.ma.array(phases, mask=np.zeros(phases.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:44:34.887257Z",
     "end_time": "2023-11-16T01:44:35.173155Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(phases, cmap=\"gray\")\n",
    "plt.title(\"Wrapped phase\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(phase_unwrapped, cmap=\"gray\")\n",
    "plt.title(\"Unwrapped phase\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now start estimating the quantitative maps (R2*, B0, S0, and phi), using the atommic library. The given echo times are TEs = [3.0, 11.5, 20.0, 28.5].\n",
    "\n",
    "Note: For proper estimation of the quantitative maps, we need to load all the four (k-space) echo times. But to begin with we will create a dummy \"4-echoed\" input, by repeating the first echo four times. This is just to verify that the code works. We will then use the actual data to estimate the quantitative maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:44:39.943150Z",
     "end_time": "2023-11-16T01:44:43.048138Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from atommic.collections.quantitative.parts.transforms import R2star_mapping, B0_phi_mapping, S0_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "axial_target_masked = axial_target * brain_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-16T01:45:49.047879Z",
     "end_time": "2023-11-16T01:45:49.151389Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:45:50.616467Z",
     "end_time": "2023-11-16T01:45:50.704257Z"
    }
   },
   "outputs": [],
   "source": [
    "axial_target_masked_tensor = np.stack([np.real(axial_target_masked), np.imag(axial_target_masked)], axis=-1)\n",
    "axial_target_masked_tensor = torch.from_numpy(axial_target_masked_tensor)\n",
    "axial_target_masked_tensor = torch.view_as_complex(axial_target_masked_tensor)\n",
    "axial_target_masked_tensor = torch.view_as_real(axial_target_masked_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:45:51.871925Z",
     "end_time": "2023-11-16T01:45:51.969674Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction = axial_target_masked_tensor.unsqueeze(0)  # then add a dummy echo dimension\n",
    "prediction = torch.cat([prediction, prediction, prediction, prediction], dim=0)  # add dummy four echo times\n",
    "TEs = [3.0, 11.5, 20.0, 28.5]  # four echo times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:45:53.292145Z",
     "end_time": "2023-11-16T01:46:06.863036Z"
    }
   },
   "outputs": [],
   "source": [
    "R2star_map = R2star_mapping(prediction, TEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:46:06.862809Z",
     "end_time": "2023-11-16T01:46:06.863677Z"
    }
   },
   "outputs": [],
   "source": [
    "R2star_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:46:06.862992Z",
     "end_time": "2023-11-16T01:46:06.971088Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(R2star_map, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:47:47.769508Z",
     "end_time": "2023-11-16T01:47:48.497377Z"
    }
   },
   "outputs": [],
   "source": [
    "mask_brain = torch.from_numpy(brain_mask).float()\n",
    "mask_brain = mask_brain.unsqueeze(0)\n",
    "head_mask = 1 - mask_brain\n",
    "fully_sampled = True\n",
    "shift = False\n",
    "fft_centered = False\n",
    "fft_normalization = \"backward\"\n",
    "spatial_dims = [-2, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:47:48.403531Z",
     "end_time": "2023-11-16T01:47:48.759026Z"
    }
   },
   "outputs": [],
   "source": [
    "B0_map = -B0_phi_mapping(\n",
    "    prediction,\n",
    "    TEs,\n",
    "    mask_brain,\n",
    "    head_mask.numpy(),\n",
    "    fully_sampled,\n",
    "    shift=shift,\n",
    "    fft_centered=fft_centered,\n",
    "    fft_normalization=fft_normalization,\n",
    "    spatial_dims=spatial_dims,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:47:59.782104Z",
     "end_time": "2023-11-16T01:47:59.914031Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(B0_map, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:48:02.210783Z",
     "end_time": "2023-11-16T01:48:02.295904Z"
    }
   },
   "outputs": [],
   "source": [
    "S0_map_real, S0_map_imag = S0_mapping(\n",
    "    prediction,\n",
    "    TEs,\n",
    "    R2star_map,\n",
    "    B0_map,\n",
    "    shift=shift,\n",
    "    fft_centered=fft_centered,\n",
    "    fft_normalization=fft_normalization,\n",
    "    spatial_dims=spatial_dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:48:03.874151Z",
     "end_time": "2023-11-16T01:48:04.307700Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(S0_map_real, cmap=\"gray\")\n",
    "plt.title(\"S0 map\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(S0_map_imag, cmap=\"gray\")\n",
    "plt.title(\"phi map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great! Or almost great. The quantitative maps of course do not look correct, since we did not use the proper echo times. So, let's go on to estimate proper quantitative maps, using the actual (four echo times of the second inversion) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's wrap up everything and create our preprocessing function for the AHEAD dataset.\n",
    "\n",
    "Note: In total we have one echo time for the 1st inversion and four echo times for the 2nd inversion. So we will have 5 echo times in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:48:15.158096Z",
     "end_time": "2023-11-16T01:48:15.194255Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:48:17.293490Z",
     "end_time": "2023-11-16T01:48:17.397181Z"
    }
   },
   "outputs": [],
   "source": [
    "def __preprocess_ahead_raw_data__(raw_data_file: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess the raw data of the AHEAD dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_data_file : str\n",
    "        Path to the raw data and coil sensitivities of the AHEAD dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kspace: np.ndarray\n",
    "        The k-space data.\n",
    "    \"\"\"\n",
    "    dataset = ismrmrd.Dataset(raw_data_file, \"dataset\", create_if_needed=False)\n",
    "    number_of_acquisitions = dataset.number_of_acquisitions()\n",
    "\n",
    "    # find the first no noise scan\n",
    "    first_scan = 0\n",
    "    for i in tqdm(range(number_of_acquisitions)):\n",
    "        head = dataset.read_acquisition(i).getHead()\n",
    "        if head.isFlagSet(ismrmrd.ACQ_IS_NOISE_MEASUREMENT):\n",
    "            first_scan = i\n",
    "            break\n",
    "\n",
    "    meas = []\n",
    "    for i in tqdm(range(first_scan, number_of_acquisitions)):\n",
    "        acq = dataset.read_acquisition(i)\n",
    "        meas.append(acq)\n",
    "\n",
    "    hdr = ismrmrd.xsd.CreateFromDocument(dataset.read_xml_header())\n",
    "\n",
    "    # Matrix size\n",
    "    enc = hdr.encoding[0]\n",
    "    enc_Nx = enc.encodedSpace.matrixSize.x\n",
    "    enc_Ny = enc.encodedSpace.matrixSize.y\n",
    "    enc_Nz = enc.encodedSpace.matrixSize.z\n",
    "\n",
    "    nCoils = hdr.acquisitionSystemInformation.receiverChannels\n",
    "\n",
    "    nslices = enc.encodingLimits.slice.maximum + 1 if enc.encodingLimits.slice is not None else 1\n",
    "    nreps = enc.encodingLimits.repetition.maximum + 1 if enc.encodingLimits.repetition is not None else 1\n",
    "    ncontrasts = enc.encodingLimits.contrast.maximum + 1 if enc.encodingLimits.contrast is not None else 1\n",
    "\n",
    "    # initialize k-space array\n",
    "    Kread = np.zeros((enc_Nx, enc_Ny, enc_Nz, nCoils), dtype=np.complex64)\n",
    "\n",
    "    # Select the appropriate measurements from the data\n",
    "    for acq in tqdm(meas):\n",
    "        head = acq.getHead()\n",
    "        if head.idx.contrast == ncontrasts - 1 and head.idx.repetition == nreps - 1 and head.idx.slice == nslices - 1:\n",
    "            head = acq.getHead()\n",
    "            ky = head.idx.kspace_encode_step_1\n",
    "            kz = head.idx.kspace_encode_step_2\n",
    "            Kread[:, ky, kz, :] = np.transpose(acq.data, (1, 0))\n",
    "\n",
    "    return Kread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's test our preprocessing function. This will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:48:28.272380Z",
     "end_time": "2023-11-16T01:48:28.325779Z"
    }
   },
   "outputs": [],
   "source": [
    "# get all files\n",
    "files = list(Path(dataset_path).iterdir())\n",
    "# get the fnames\n",
    "fnames = [str(file).split('/')[-1].split('_')[1].split('.')[0] for file in files if \"coilsens\" in file.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:48:29.937933Z",
     "end_time": "2023-11-16T01:48:30.586895Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's do the first subject in our list\n",
    "fname = fnames[0]\n",
    "print(f\"Processing subject {fname}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:48:30.553574Z",
     "end_time": "2023-11-16T01:48:30.685283Z"
    }
   },
   "outputs": [],
   "source": [
    "# get all files for this subject from files\n",
    "subject_files = [file for file in files if fname in file.name]\n",
    "raw_data_files = [file for file in subject_files if \"coilsens\" not in file.name and \"inv1\" not in file.name]\n",
    "raw_data_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T01:48:32.064638Z",
     "end_time": "2023-11-16T02:19:05.930571Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess the raw data\n",
    "kspaces = [__preprocess_ahead_raw_data__(str(x)) for x in raw_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:19:05.923710Z",
     "end_time": "2023-11-16T02:19:05.931703Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Number of kspaces: {len(kspaces)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's wrap up a function to get different planes from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:19:05.923867Z",
     "end_time": "2023-11-16T02:19:05.931780Z"
    }
   },
   "outputs": [],
   "source": [
    "def __get_plane__(data: np.ndarray, data_on_kspace: bool = True, plane: str = \"sagittal\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the given plane from the data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        The data to get the plane from.\n",
    "    data_on_kspace : bool, optional\n",
    "        Whether the data is on the kspace or not. The default is True.\n",
    "    plane : str, optional\n",
    "        The plane to get the kspace and coil sensitivities from. The default is \"sagittal\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: np.ndarray\n",
    "        The data of the given plane.\n",
    "    \"\"\"\n",
    "    if not data_on_kspace:\n",
    "        data = np.fft.fftn(data, axes=(0, 1, 2))\n",
    "\n",
    "    if plane == \"axial\":\n",
    "        data = np.transpose(data, (2, 0, 1, 3))\n",
    "    elif plane == \"coronal\":\n",
    "        data = np.transpose(data, (1, 0, 2, 3))\n",
    "\n",
    "    # all planes need to be rotated by 90 degrees in x-y to get the correct orientation\n",
    "    data = np.rot90(data, k=1, axes=(1, 2))\n",
    "\n",
    "    if not data_on_kspace:\n",
    "        data = np.fft.ifftn(data, axes=(0, 1, 2))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:19:05.923958Z",
     "end_time": "2023-11-16T02:19:05.931826Z"
    }
   },
   "outputs": [],
   "source": [
    "axial_kspaces = [__get_plane__(x, data_on_kspace=True, plane=\"axial\") for x in kspaces]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same for the coil sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:19:05.924038Z",
     "end_time": "2023-11-16T02:19:05.931870Z"
    }
   },
   "outputs": [],
   "source": [
    "def __preprocess_ahead_coil_sensitivities__(coil_sensitivities_file: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess the coil sensitivities of the AHEAD dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coil_sensitivities_file : str\n",
    "        Path to the coil sensitivities of the AHEAD dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coil_sensitivities: np.ndarray\n",
    "        The coil sensitivities.\n",
    "    \"\"\"\n",
    "    # load the coil sensitivities\n",
    "    coil_sensitivities = h5py.File(coil_sensitivities_file, \"r\")\n",
    "\n",
    "    # get the coil sensitivities\n",
    "    coil_sensitivities_real = np.array(coil_sensitivities[\"0real\"])\n",
    "    coil_sensitivities_imag = np.array(coil_sensitivities[\"1imag\"])\n",
    "    coil_sensitivities = coil_sensitivities_real + 1j * coil_sensitivities_imag\n",
    "\n",
    "    # transpose to get the correct shape, i.e. (x, y, z, coils)\n",
    "    coil_sensitivities = np.transpose(coil_sensitivities, (3, 2, 1, 0))\n",
    "\n",
    "    return coil_sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:19:05.924128Z",
     "end_time": "2023-11-16T02:19:05.931915Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities_file = [file for file in subject_files if \"coilsens\" in file.name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:19:05.924241Z",
     "end_time": "2023-11-16T02:19:44.813148Z"
    }
   },
   "outputs": [],
   "source": [
    "coil_sensitivities = __preprocess_ahead_coil_sensitivities__(str(coil_sensitivities_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:19:44.812831Z",
     "end_time": "2023-11-16T02:22:38.604132Z"
    }
   },
   "outputs": [],
   "source": [
    "axial_coil_sensitivities = __get_plane__(coil_sensitivities, data_on_kspace=False, plane=\"axial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's wrap up a function that transforms the kspaces to image space and computes target images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:22:38.603703Z",
     "end_time": "2023-11-16T02:22:38.605364Z"
    }
   },
   "outputs": [],
   "source": [
    "def __compute_targets__(\n",
    "        kspace: np.ndarray, coil_sensitivities: np.ndarray, coil_dim: int = -1\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the target images from the kspace and coil sensitivities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kspace : np.ndarray\n",
    "        The kspace.\n",
    "    coil_sensitivities : np.ndarray\n",
    "        The coil sensitivities.\n",
    "    coil_dim : int, optional\n",
    "        The dimension of the coil sensitivities. The default is -1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image_space : np.ndarray\n",
    "        The image space.\n",
    "    target_image : np.ndarray\n",
    "        The target image.\n",
    "    \"\"\"\n",
    "    # get the image space\n",
    "    image_space = np.fft.fftshift(\n",
    "        np.fft.ifftn(np.fft.fftshift(kspace, axes=(0, 1, 2)), axes=(0, 1, 2)), axes=(0, 1, 2)\n",
    "    )\n",
    "\n",
    "    # compute the target\n",
    "    target = np.sum(image_space * np.conj(coil_sensitivities), axis=coil_dim)\n",
    "\n",
    "    return image_space, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:22:38.603873Z",
     "end_time": "2023-11-16T02:32:11.236339Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute the image spaces and targets\n",
    "axial_image_spaces = []\n",
    "axial_targets = []\n",
    "for x in axial_kspaces:\n",
    "    axial_image_space, axial_target = __compute_targets__(x, axial_coil_sensitivities, coil_dim=-1)\n",
    "    axial_image_spaces.append(axial_image_space)\n",
    "    axial_targets.append(axial_target)\n",
    "axial_image_space = np.stack(axial_image_spaces, axis=1)\n",
    "axial_target = np.stack(axial_targets, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's visualize the target images of 2nd inversion for the four echo times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:38:52.813706Z",
     "end_time": "2023-11-16T02:38:53.783437Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(4, 4, 1)\n",
    "plt.imshow(np.abs(axial_target[slice_idx, 0, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude echo 1\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 2)\n",
    "plt.imshow(np.angle(axial_target[slice_idx, 0, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Phase echo 1\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 3)\n",
    "plt.imshow(np.real(axial_target[slice_idx, 0, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Real part echo 1\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 4)\n",
    "plt.imshow(np.imag(axial_target[slice_idx, 0, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part echo 1\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 5)\n",
    "plt.imshow(np.abs(axial_target[slice_idx, 1, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude echo 2\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 6)\n",
    "plt.imshow(np.angle(axial_target[slice_idx, 1, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Phase echo 2\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 7)\n",
    "plt.imshow(np.real(axial_target[slice_idx, 1, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Real part echo 2\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 8)\n",
    "plt.imshow(np.imag(axial_target[slice_idx, 1, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part echo 2\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 9)\n",
    "plt.imshow(np.abs(axial_target[slice_idx, 2, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude echo 3\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 10)\n",
    "plt.imshow(np.angle(axial_target[slice_idx, 2, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Phase echo 3\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 11)\n",
    "plt.imshow(np.real(axial_target[slice_idx, 2, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Real part echo 3\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 12)\n",
    "plt.imshow(np.imag(axial_target[slice_idx, 2, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part echo 3\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 13)\n",
    "plt.imshow(np.abs(axial_target[slice_idx, 3, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Magnitude echo 4\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 14)\n",
    "plt.imshow(np.angle(axial_target[slice_idx, 3, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Phase echo 4\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 15)\n",
    "plt.imshow(np.real(axial_target[slice_idx, 3, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Real part echo 4\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(4, 4, 16)\n",
    "plt.imshow(np.imag(axial_target[slice_idx, 3, :, :]), cmap=\"gray\")\n",
    "plt.title(\"Imaginary part echo 4\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alright, now we have our kspaces and coil sensitivities in the axial plane for all four echo times for one subject. Let's finish with our preprocessing transforms by wrapping up a function that computes brain and head masks. Note that the brain and head masks are the same for all echo times, thus we can compute them only for one and use them for all. Then we are done with the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T02:39:06.765050Z",
     "end_time": "2023-11-16T02:39:06.858882Z"
    }
   },
   "outputs": [],
   "source": [
    "def __compute_masks__(target_image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the brain and head masks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_image : np.ndarray\n",
    "        The target image.\n",
    "    Returns\n",
    "    -------\n",
    "    brain_mask : np.ndarray\n",
    "        The brain mask.\n",
    "    head_mask : np.ndarray\n",
    "        The head mask.\n",
    "    \"\"\"\n",
    "    # compute head and brain mask\n",
    "    head_masks = []\n",
    "    brain_masks = []\n",
    "    for _slice_idx_ in tqdm(range(target_image.shape[0])):\n",
    "        # calculate otsu's threshold\n",
    "        threshold = threshold_otsu(np.abs(target_image[_slice_idx_]))\n",
    "        # get the connected components and apply threshold\n",
    "        axial_target_cc = measure.label(np.abs(target_image[_slice_idx_]) > threshold * 2) + measure.label(\n",
    "            np.abs(target_image[_slice_idx_]) > threshold)\n",
    "        # Get mask\n",
    "        skull_mask = np.where(axial_target_cc != 0, 1, 0)\n",
    "        # get the convex hull\n",
    "        brain_mask = convex_hull_image(skull_mask) * (1 - skull_mask)\n",
    "        # perform binary erosion to remove skull\n",
    "        brain_mask = binary_erosion(brain_mask, iterations=4)\n",
    "        # get the convex hull of the brain mask\n",
    "        brain_mask = convex_hull_image(brain_mask)\n",
    "        # threshold the brain mask\n",
    "        brain_mask = np.where(np.abs(target_image[_slice_idx_]) * brain_mask > threshold / 2, 1, 0)\n",
    "        # perform binary erosion to remove skull\n",
    "        brain_mask = binary_erosion(brain_mask, iterations=4)\n",
    "        # perform binary dilation to get the brain mask\n",
    "        brain_mask = binary_dilation(brain_mask, iterations=4)\n",
    "        # fill holes in the brain mask\n",
    "        brain_mask = binary_fill_holes(brain_mask)\n",
    "        # get the convex hull of the brain mask\n",
    "        brain_mask = convex_hull_image(brain_mask)\n",
    "        brain_masks.append(brain_mask)\n",
    "        head_masks.append(1 - brain_mask)\n",
    "    head_mask = np.stack(head_masks, axis=0)\n",
    "    brain_mask = np.stack(brain_masks, axis=0)\n",
    "    return brain_mask.astype(np.float32), head_mask.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the brain and head masks are the same for all echoes\n",
    "brain_mask, head_mask = __compute_masks__(axial_target[:, 0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's visualize the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(brain_mask[slice_idx], cmap=\"gray\")\n",
    "plt.title(\"Brain mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(head_mask[slice_idx], cmap=\"gray\")\n",
    "plt.title(\"Head mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are done with the preprocessing! Let's go on and compute proper quantitative maps from the four echo times.\n",
    "\n",
    "We will use the atommic package for this. The `R2star_B0_real_S0_complex_mapping' will allow us to compute the R2*, B0, S0, and phi maps.\n",
    "\n",
    "We only need to convert our target images to torch tensors and pass them to the mapping function with the corresponding echo times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atommic.collections.quantitative.parts.transforms import R2star_B0_S0_phi_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __compute_quantitative_maps__(\n",
    "        target_images: np.ndarray,\n",
    "        TEs: List[float],\n",
    "        brain_mask: np.ndarray,\n",
    "        head_mask: np.ndarray,\n",
    "        fully_sampled: bool = True,\n",
    "        shift: bool = False,\n",
    "        fft_centered: bool = False,\n",
    "        fft_normalization: str = \"backward\",\n",
    "        spatial_dims=None,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the quantitative maps.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_images : np.ndarray\n",
    "        The target images.\n",
    "    TEs : List[float]\n",
    "        The echo times.\n",
    "    brain_mask : np.ndarray\n",
    "        The brain mask.\n",
    "    head_mask : np.ndarray\n",
    "        The head mask.\n",
    "    fully_sampled : bool, optional\n",
    "        Whether the data is fully sampled or not. The default is True.\n",
    "    shift : bool, optional\n",
    "        Whether to shift the kspace or not. The default is False.\n",
    "    fft_centered : bool, optional\n",
    "        Whether the fft is centered or not. The default is False.\n",
    "    fft_normalization : str, optional\n",
    "        The fft normalization. The default is \"backward\".\n",
    "    spatial_dims : List[int], optional\n",
    "        The spatial dimensions. The default is [-2, -1].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    multiple_echoes_target : np.ndarray\n",
    "        The stacked target image from multiple echoes.\n",
    "    R2star_map : np.ndarray\n",
    "        The R2* map.\n",
    "    S0_map : np.ndarray\n",
    "        The S0 map.\n",
    "    B0_map : np.ndarray\n",
    "        The B0 map.\n",
    "    phi_map : np.ndarray\n",
    "        The phase map.\n",
    "    \"\"\"\n",
    "    # stack real and imaginary part of the target image\n",
    "    if spatial_dims is None:\n",
    "        spatial_dims = [-2, -1]\n",
    "    multiple_echoes_target_tensor = np.stack([np.real(target_images), np.imag(target_images)], axis=-1)\n",
    "    # convert to torch tensor\n",
    "    multiple_echoes_target_tensor = torch.from_numpy(multiple_echoes_target_tensor)\n",
    "    # verify the tensor will be complex valued\n",
    "    multiple_echoes_target_tensor = torch.view_as_complex(multiple_echoes_target_tensor)\n",
    "    # verify the tensor can be converted to real valued, with stacked real and imag parts on the last dimension\n",
    "    multiple_echoes_target_tensor = torch.view_as_real(multiple_echoes_target_tensor)\n",
    "\n",
    "    brain_mask = torch.from_numpy(brain_mask).unsqueeze(1)\n",
    "    head_mask = torch.from_numpy(head_mask).unsqueeze(1)\n",
    "\n",
    "    R2star_maps = []\n",
    "    S0_maps = []\n",
    "    B0_maps = []\n",
    "    phi_maps = []\n",
    "    for slice_idx in tqdm(range(multiple_echoes_target_tensor.shape[0])):\n",
    "        # compute the quantitative maps\n",
    "        R2star_map, S0_map, B0_map, phi_map = R2star_B0_S0_phi_mapping(\n",
    "            prediction=multiple_echoes_target_tensor[slice_idx],\n",
    "            TEs=TEs,\n",
    "            brain_mask=brain_mask[slice_idx],\n",
    "            head_mask=head_mask[slice_idx],\n",
    "            fully_sampled=fully_sampled,\n",
    "            shift=shift,\n",
    "            fft_centered=fft_centered,\n",
    "            fft_normalization=fft_normalization,\n",
    "            spatial_dims=spatial_dims\n",
    "        )\n",
    "        R2star_maps.append(R2star_map)\n",
    "        S0_maps.append(S0_map)\n",
    "        B0_maps.append(B0_map[0])\n",
    "        phi_maps.append(phi_map)\n",
    "\n",
    "    R2star_maps = torch.stack(R2star_maps, dim=0).numpy()\n",
    "    S0_maps = torch.stack(S0_maps, dim=0).numpy()\n",
    "    B0_maps = torch.stack(B0_maps, dim=0).numpy()\n",
    "    phi_maps = torch.stack(phi_maps, dim=0).numpy()\n",
    "\n",
    "    return torch.view_as_complex(multiple_echoes_target_tensor).numpy(), R2star_maps, S0_maps, B0_maps, phi_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for reminder, those are the TEs of the dataset\n",
    "TEs = [3.0, 11.5, 20.0, 28.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will do 1 slice for ease of this example\n",
    "multiple_echoes_target_tensor, R2star_map, S0_map, B0_map, phi_map = __compute_quantitative_maps__(\n",
    "    axial_target[slice_idx:slice_idx+1],\n",
    "    TEs,\n",
    "    brain_mask[slice_idx:slice_idx+1],\n",
    "    head_mask[slice_idx:slice_idx+1],\n",
    "    fully_sampled=True,\n",
    "    shift=False,\n",
    "    fft_centered=False,\n",
    "    fft_normalization=\"backward\",\n",
    "    spatial_dims=[-2, -1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Shape of the target tensor: {multiple_echoes_target_tensor.shape}\\n\"\n",
    "    f\"Shape of the R2* map: {R2star_map.shape}\\n\"\n",
    "    f\"Shape of the S0 map: {S0_map.shape}\\n\"\n",
    "    f\"Shape of the B0 map: {B0_map.shape}\\n\"\n",
    "    f\"Shape of the phi map: {phi_map.shape}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(R2star_map[0], cmap=\"gray\")\n",
    "plt.title(\"R2*\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(S0_map[0], cmap=\"gray\")\n",
    "plt.title(\"S0\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(B0_map[0], cmap=\"gray\")\n",
    "plt.title(\"B0\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(phi_map[0], cmap=\"gray\")\n",
    "plt.title(\"Phi\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awesome! We have computed the R2*, B0, S0, and phi maps from the four echo times!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we have shown how to preprocess the AHEAD dataset and compute the R2*, B0, S0, and phi maps from data with multiple echo times.\n",
    "\n",
    "You can now download the AHEAD dataset and use the preprocessing script to batch process multiple subjects and save the inputs to disk. You can then use the preprocessed data to train a Deep Learning quantitative model by configuring the `data` section of the `config.yaml` file.\n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Caan, Matthan, 2022, \"Quantitative motion-corrected 7T sub-millimeter raw MRI database of the adult lifespan\", https://doi.org/10.34894/IHZGQM, DataverseNL, V1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
