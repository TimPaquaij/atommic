
defaults:
  - override hydra/launcher: atommic_launcher

hydra:
  # Helper arguments to ensure all hyper parameter runs are from the directory that launches the script.
  sweep:
    dir: "."
    subdir: "."

  # Define all the hyper parameters here
  sweeper:
    params:
      # Place all the parameters you wish to search over here (corresponding to the rest of the config)
      # NOTE: Make sure that there are no spaces between the commas that separate the config params !
      model.mc_run: 1,2,3,4,5

  # Arguments to the process launcher
  launcher:
    num_gpus: -1  # Number of gpus to use. Each run works on a single GPU.
    jobs_per_gpu: 1  # If each GPU has large memory, you can run multiple jobs on the same GPU for faster results (until OOM)

pretrained: true
checkpoint: /scratch/tmpaquaij/Results/atommic/mltrs/trained_models/SKMTEA/MTLRS_SENSE/default/2024-01-17_16-08-12/checkpoints/default--val_loss=0.0068-epoch=10-last.ckpt
mode: test

model:
  model_name: MTLRS
  mc_run: 1
  joint_reconstruction_segmentation_module_cascades: 5
  task_adaption_type: multi_task_learning
  cascade_nr_hidden_states: 1
  use_reconstruction_module: true
  reconstruction_module_recurrent_layer: IndRNN
  reconstruction_module_conv_filters:
    - 64
    - 64
    - 2
  reconstruction_module_conv_kernels:
    - 5
    - 3
    - 3
  reconstruction_module_conv_dilations:
    - 1
    - 2
    - 1
  reconstruction_module_conv_bias:
    - true
    - true
    - false
  reconstruction_module_conv_dropout:
    - 0.5
    - 0.5
    - 0
  reconstruction_module_conv_activations:
    - RELU
    - RELU
    - None
  reconstruction_module_recurrent_filters:
    - 64
    - 64
    - 0
  reconstruction_module_recurrent_kernels:
    - 1
    - 1
    - 0
  reconstruction_module_recurrent_dilations:
    - 1
    - 1
    - 0
  reconstruction_module_recurrent_bias:
    - true
    - true
    - false
  reconstruction_module_recurrent_dropout:
    - 0.5
    - 0.5
    - 0
  reconstruction_module_depth: 2
  reconstruction_module_time_steps: 8
  reconstruction_module_conv_dim: 2
  reconstruction_module_num_cascades: 1
  reconstruction_module_dimensionality: 2
  reconstruction_module_no_dc: true
  reconstruction_module_keep_prediction: true
  reconstruction_module_accumulate_predictions: true
  segmentation_module: AttentionUNet
  segmentation_module_input_channels: 1
  segmentation_module_output_channels: 4
  segmentation_module_channels: 64
  segmentation_module_pooling_layers: 2
  segmentation_module_dropout: 0.0
  segmentation_loss:
    dice: 1.0
    cross_entropy: 1
  dice_loss_include_background: true  # always set to true if the background is removed
  dice_loss_to_onehot_y: false
  dice_loss_sigmoid: false
  dice_loss_softmax: false
  dice_loss_other_act: none
  dice_loss_squared_pred: false
  dice_loss_jaccard: false
  dice_loss_flatten: false
  dice_loss_reduction: mean_batch
  dice_loss_smooth_nr: 1e-5
  dice_loss_smooth_dr: 1e-5
  dice_loss_batch: true
  dice_metric_include_background: true  # always set to true if the background is removed
  dice_metric_to_onehot_y: false
  dice_metric_sigmoid: false
  dice_metric_softmax: false
  dice_metric_other_act: none
  dice_metric_squared_pred: false
  dice_metric_jaccard: false
  dice_metric_flatten: false
  dice_metric_reduction: mean_batch
  dice_metric_smooth_nr: 1e-5
  dice_metric_smooth_dr: 1e-5
  dice_metric_batch: true
  segmentation_classes_thresholds: [0.5, 0.5, 0.5, 0.5]
  segmentation_activation: sigmoid
  reconstruction_loss:
    l1: 1.0
    ssim: 1.0
  kspace_reconstruction_loss: false
  total_reconstruction_loss_weight: 0.9
  total_segmentation_loss_weight: 0.1
  complex_valued_type: stacked  # stacked, complex_abs, complex_sqrt_abs
  fft_centered: true
  fft_normalization: ortho
  spatial_dims:
    - -2
    - -1
  magnitude_input: false
  log_multiple_modalities: false  # log all modalities in the same image, e.g. T1, T2, T1ce, FLAIR will be concatenated
  normalization_type: minmax
  normalize_segmentation_output: true
  unnormalize_loss_inputs: false
  unnormalize_log_outputs: false
  complex_data: true
  consecutive_slices: 1
  dimensionality: 2
  coil_combination_method: SENSE
  coil_dim: 1
  estimate_coil_sensitivity_maps_with_nn: false
  ssdu: false
  n2r: false

  test_ds:
    data_path:  /data/projects/utwente/recon/SKM-TEA/v1-release/json/files_recon_calib-24_MTR_005_test.json
    coil_sensitivity_maps_path: None
    mask_path: None
    noise_path: None
    initial_predictions_path: None
    dataset_format:
    - custom_masking
    - skm-tea-echo1
    - lateral
    sample_rate: 1
    volume_sample_rate: None
    use_dataset_cache: false
    dataset_cache_file: None
    num_cols: None
    consecutive_slices: 1
    data_saved_per_slice: false
    complex_target: true
    log_images_rate: 1e-2
    apply_prewhitening: false
    apply_gcc: false
    coil_combination_method: SENSE
    dimensionality: 2
    mask_args:
      type: gaussian2d  # the mask will be loaded from the dataset, but we need to specify the type here
      accelerations:
        - 8  # 4, 6, 8, 10, 12, 16
      shift_mask: false
      use_seed: true
    partial_fourier_percentage: 0.0
    remask: false
    ssdu: false
    n2r: false
    unsupervised_masked_target: false
    crop_size: None
    kspace_crop: false
    crop_before_masking: true
    kspace_zero_filling_size: None
    normalize_inputs: true
    normalization_type: minmax
    kspace_normalization: false
    fft_centered: true
    fft_normalization: ortho
    spatial_dims:
      - -2
      - -1
    coil_dim: 1
    use_seed: true
    segmentations_path: /data/projects/utwente/recon/SKM-TEA/v1-release/segmentation_masks/raw-data-track/
    segmentation_classes: 4
    complex_data: true
    batch_size: 1
    shuffle: false
    num_workers: 4
    pin_memory: false
    drop_last: false
# Hydra arguments necessary for hyperparameter optimization


trainer:
  strategy: ddp_find_unused_parameters_true
  accelerator: gpu
  devices: 1
  num_nodes: 1
  max_epochs: 1
  precision: 16-mixed
  enable_checkpointing: false
  logger: false
  log_every_n_steps: 50
  check_val_every_n_epoch: -1
  max_steps: -1

exp_manager:


  # Add a unique name for all hyper parameter arguments to allow continued training.
  # NOTE: It is necessary to add all hyperparameter arguments to the name !
  # This ensures successful restoration of model runs in case HP search crashes.
  name: MTLRS--MC-${model.mc_run}

  exp_dir: /data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/2024-01-17_16-08-12 # Can be set by the user.
  checkpoint_callback_params:
    save_top_k: 1  # Dont save too many .ckpt files during HP search
    always_save_atommic: True # saves the checkpoints as atommic files for fast checking of results later


  # We highly recommend use of any experiment tracking took to gather all the experiments in one location
  create_wandb_logger: false
  wandb_logger_kwargs:
    project: "MTLRS_Multi_run"

  # HP Search may crash due to various reasons, best to attempt continuation in order to
  # resume from where the last failure case occured.
  resume_if_exists: true
  resume_ignore_no_checkpoint: true