{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-20T18:23:29.762329Z",
     "end_time": "2024-03-20T18:23:29.802640Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from typing import  Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "__author__ = \"Dimitris Karkalousos\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Optional\n",
    "from atommic.core.classes.loss import Loss\n",
    "\n",
    "class FocalLoss(Loss):\n",
    "    \"\"\"Wrapper around PyTorch's CrossEntropyLoss to support 2D and 3D inputs.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_samples: int = 50,\n",
    "        ignore_index: int = -100,\n",
    "        reduction: str = \"none\",\n",
    "        label_smoothing: float = 0.0,\n",
    "        weight: torch.Tensor = None,\n",
    "        gamma: float = 2,\n",
    "        alpha: float = 0.25,\n",
    "    ):\n",
    "        \"\"\"Inits :class:`CrossEntropyLoss`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_samples : int, optional\n",
    "            Number of Monte Carlo samples, by default 50\n",
    "        ignore_index : int, optional\n",
    "            Index to ignore, by default -100\n",
    "        reduction : str, optional\n",
    "            Reduction method, by default \"none\"\n",
    "        label_smoothing : float, optional\n",
    "            Label smoothing, by default 0.0\n",
    "        weight : torch.Tensor, optional\n",
    "            Weight for each class, by default None\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mc_samples = num_samples\n",
    "        self.ignore_index =ignore_index\n",
    "        self.weight = weight\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.reduction = reduction\n",
    "        self.gamma =gamma\n",
    "        self.alpha =alpha\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, target: torch.Tensor, _input: torch.Tensor, pred_log_var: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of :class:`CrossEntropyLoss`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        target : torch.Tensor\n",
    "            Target tensor. Shape: (batch_size, num_classes, *spatial_dims)\n",
    "        _input : torch.Tensor\n",
    "            Prediction tensor. Shape: (batch_size, num_classes, *spatial_dims)\n",
    "        pred_log_var : torch.Tensor, optional\n",
    "            Prediction log variance tensor. Shape: (batch_size, num_classes, *spatial_dims). Default is ``None``.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Loss tensor. Shape: (batch_size, *spatial_dims)\n",
    "        \"\"\"\n",
    "        # In case we do not have a batch dimension, add it\n",
    "        if _input.dim() == 3:\n",
    "            _input = _input.unsqueeze(0)\n",
    "        if target.dim() == 3:\n",
    "            target = target.unsqueeze(0)\n",
    "\n",
    "\n",
    "        cross_entropy = torch.nn.CrossEntropyLoss(\n",
    "            #weight=self.weight.to(_input),\n",
    "            ignore_index=self.ignore_index,\n",
    "            reduction=self.reduction,\n",
    "            label_smoothing=self.label_smoothing,\n",
    "        )\n",
    "\n",
    "        if self.mc_samples == 1 or pred_log_var is None:\n",
    "            ce_loss = cross_entropy(_input.float(), target.float())\n",
    "            pt = torch.exp(-ce_loss)\n",
    "            focal_loss = (self.alpha * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "\n",
    "            return focal_loss\n",
    "\n",
    "        pred_shape = [self.mc_samples, *_input.shape]\n",
    "        noise = torch.randn(pred_shape, device=_input.device)\n",
    "        noisy_pred = _input.unsqueeze(0) + torch.sqrt(torch.exp(pred_log_var)).unsqueeze(0) * noise\n",
    "        noisy_pred = noisy_pred.view(-1, *_input.shape[1:])\n",
    "        tiled_target = target.unsqueeze(0).tile((self.mc_samples,)).view(-1, *target.shape[1:])\n",
    "        loss = cross_entropy(noisy_pred, tiled_target).to(target).view(self.mc_samples, -1, *_input.shape[-2:]).mean(0)\n",
    "        return loss.mean()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T18:23:37.741572Z",
     "end_time": "2024-03-20T18:23:37.785252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def one_hot(labels: torch.Tensor, num_classes: int, dtype: torch.dtype = torch.float, dim: int = 1) -> torch.Tensor:\n",
    "    \"\"\"Convert labels to one-hot representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: torch.Tensor\n",
    "        the labels of shape [BNHW[D]].\n",
    "    num_classes: int\n",
    "        number of classes.\n",
    "    dtype: torch.dtype\n",
    "        the data type of the returned tensor.\n",
    "    dim: int\n",
    "        the dimension to expand the one-hot tensor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The one-hot representation of the labels.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> labels = torch.tensor([[[[0, 1, 2]]]])\n",
    "    >>> one_hot(labels, num_classes=3)\n",
    "    tensor([[[[1., 0., 0.],\n",
    "                [0., 1., 0.],\n",
    "                [0., 0., 1.]]]])\n",
    "    \"\"\"\n",
    "    # if `dim` is bigger, add singleton dim at the end\n",
    "    if labels.ndim < dim + 1:\n",
    "        shape = list(labels.shape) + [1] * (dim + 1 - len(labels.shape))\n",
    "        labels = torch.reshape(labels, shape)\n",
    "    sh = list(labels.shape)\n",
    "    sh[dim] = num_classes\n",
    "    o = torch.zeros(size=sh, dtype=dtype, device=labels.device)\n",
    "    labels = o.scatter_(dim=dim, index=labels.long(), value=1)\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T20:58:10.244359Z",
     "end_time": "2024-03-20T20:58:10.283518Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def get_scaled_image(\n",
    "    x: Union[torch.Tensor, np.ndarray], percentile=0.99, clip=False\n",
    "):\n",
    "  \"\"\"Scales image by intensity percentile (and optionally clips to [0, 1]).\n",
    "\n",
    "  Args:\n",
    "    x (torch.Tensor | np.ndarray): The image to process.\n",
    "    percentile (float): The percentile of magnitude to scale by.\n",
    "    clip (bool): If True, clip values between [0, 1]\n",
    "\n",
    "  Returns:\n",
    "    torch.Tensor | np.ndarray: The scaled image.\n",
    "  \"\"\"\n",
    "  is_numpy = isinstance(x, np.ndarray)\n",
    "  if is_numpy:\n",
    "    x = torch.as_tensor(x)\n",
    "\n",
    "  scale_factor = torch.quantile(x, percentile)\n",
    "  x = x / scale_factor\n",
    "  if clip:\n",
    "    x = torch.clip(x, 0, 1)\n",
    "\n",
    "  if is_numpy:\n",
    "    x = x.numpy()\n",
    "\n",
    "  return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T18:23:40.986793Z",
     "end_time": "2024-03-20T18:23:40.989345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "with h5py.File('/data/projects/utwente/recon/SKM-TEA_small/v1-release/files_recon_calib-24/MTR_135.h5', \"r\") as f:\n",
    "    kspace_small= f[\"kspace\"][:, :, :, :, :]  # Shape: (x, ky, kz, #echos, #coils)\n",
    "    maps_small = f[\"maps\"][:, :, :, :, :]      # Shape: (x, ky, kz, #coils, #maps) - maps are the same for both echos\n",
    "\n",
    "with h5py.File('/data/projects/recon/data/public/multitask/skm-tea/v1-release/files_recon_calib-24/MTR_135.h5', \"r\") as f:\n",
    "    kspace_org= f[\"kspace\"][:, :, :, :, :]  # Shape: (x, ky, kz, #echos, #coils)\n",
    "    maps_org = f[\"maps\"][:, :, :, :, :]      # Shape: (x, ky, kz, #coils, #maps) - maps are the same for both echos\n",
    "\n",
    "segmentation_one_small = nib.load('/data/projects/utwente/recon/SKM-TEA_small/v1-release/segmentation_masks/raw-data-track/MTR_135.nii.gz').get_fdata()\n",
    "\n",
    "segmentation_one_org = nib.load('/data/projects/recon/data/public/multitask/skm-tea/v1-release/segmentation_masks/raw-data-track/MTR_135.nii.gz').get_fdata()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T18:23:44.138181Z",
     "end_time": "2024-03-20T18:23:51.590963Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 168, 2, 8)\n",
      "(512, 512, 168, 8, 1)\n",
      "(88, 256, 208, 2, 8)\n",
      "(88, 256, 208, 1, 8)\n",
      "(512, 512, 168)\n",
      "(88, 256, 208, 4)\n"
     ]
    }
   ],
   "source": [
    "print(kspace_org.shape)\n",
    "print(maps_org.shape)\n",
    "print(kspace_small.shape)\n",
    "print(maps_small.shape)\n",
    "print(segmentation_one_org.shape)\n",
    "print(segmentation_one_small.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T18:23:51.593799Z",
     "end_time": "2024-03-20T18:23:51.596485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7ff1889d1ae0>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplot(3,1,1)\n",
    "plt.imshow(get_scaled_image(np.abs(kspace_org[0,48:-48,40:-40,0,0]),0.99, clip=True),cmap='gray')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(get_scaled_image(np.abs(kspace_small[87,:,:,0,0]),0.99, clip=True),cmap='gray')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(get_scaled_image(np.abs(maps_small[84,:,:,0,0]),0.99, clip=True),cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T18:23:51.597523Z",
     "end_time": "2024-03-20T18:23:51.779935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 256, 216])\n",
      "tensor(3.8275) tensor(3.8275)\n"
     ]
    }
   ],
   "source": [
    "seed =1\n",
    "\n",
    "input = torch.randn((5,5,256,216))\n",
    "target = torch.randn((5,5,256,216))\n",
    "target_one_hot = one_hot(torch.argmax(torch.abs(target),dim=1).unsqueeze(1),num_classes=target.shape[1]).float()\n",
    "print(target_one_hot.shape)\n",
    "target_indices =torch.argmax(torch.abs(target),dim=1)\n",
    "loss = torch.nn.functional.cross_entropy(input,target_one_hot).mean()\n",
    "loss_indices = torch.nn.functional.cross_entropy(input,target_indices).mean()\n",
    "print(loss,loss_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T21:07:45.736972Z",
     "end_time": "2024-03-20T21:07:45.852961Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T20:21:24.985927Z",
     "end_time": "2024-03-20T20:21:25.026324Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
