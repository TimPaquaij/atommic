{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from typing import Union, Sequence\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import pandas as pd\n",
    "from skimage.color import label2rgb\n",
    "import torch\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import seaborn as sns\n",
    "from atommic.collections.reconstruction.metrics.reconstruction_metrics import ssim,psnr,haarpsi3d,vsi3d\n",
    "from atommic.collections.segmentation.metrics.segmentation_metrics import asd, dice_metric, hausdorff_distance_95_metric, f1_per_class_metric,iou_metric\n",
    "from atommic.collections.segmentation.losses.dice import one_hot\n",
    "import functools\n",
    "\n",
    "\n",
    "# Function for plotting MRI scans\n",
    "\n",
    "\n",
    "def get_scaled_image(\n",
    "        x: Union[torch.Tensor, np.ndarray], percentile=0.99, clip=False\n",
    "):\n",
    "    \"\"\"Scales image by intensity percentile (and optionally clips to [0, 1]).\n",
    "\n",
    "    Args:\n",
    "      x (torch.Tensor | np.ndarray): The image to process.\n",
    "      percentile (float): The percentile of magnitude to scale by.\n",
    "      clip (bool): If True, clip values between [0, 1]\n",
    "\n",
    "    Returns:\n",
    "      torch.Tensor | np.ndarray: The scaled image.\n",
    "    \"\"\"\n",
    "    is_numpy = isinstance(x, np.ndarray)\n",
    "    if is_numpy:\n",
    "        x = torch.as_tensor(x)\n",
    "\n",
    "    scale_factor = torch.quantile(x, percentile)\n",
    "    x = x / scale_factor\n",
    "    if clip:\n",
    "        x = torch.clip(x, 0, 1)\n",
    "\n",
    "    if is_numpy:\n",
    "        x = x.numpy()\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def plot_images(\n",
    "        images, processor=None, disable_ticks=True, titles: Sequence[str] = None,\n",
    "        ylabel: str = None, xlabels: Sequence[str] = None, cmap: str = \"gray\",\n",
    "        show_cbar: bool = False, overlay=None, opacity: float = 0.4,\n",
    "        hsize=5, wsize=5, axs=None, fontsize=20,text=None,show_cbar_overlay: bool=False,ticks:bool=False,\n",
    "):\n",
    "    \"\"\"Plot multiple images in a single row.\n",
    "\n",
    "    Add an overlay with the `overlay=` argument.\n",
    "    Add a colorbar with `show_cbar=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_default_values(x, default=\"\"):\n",
    "        if x is None:\n",
    "            return [default] * len(images)\n",
    "        return x\n",
    "\n",
    "    titles = get_default_values(titles)\n",
    "    ylabels = get_default_values(images)\n",
    "    xlabels = get_default_values(xlabels)\n",
    "\n",
    "    N = len(images)\n",
    "    if axs is None:\n",
    "        fig, axs = plt.subplots(1, N, figsize=(wsize * N, hsize))\n",
    "    else:\n",
    "        assert len(axs) >= N\n",
    "        fig = axs.flatten()[0].get_figure()\n",
    "    k = 0\n",
    "    for ax, img, title, xlabel in zip(axs, images, titles, xlabels):\n",
    "        if processor is not None:\n",
    "            img = processor(img)\n",
    "        if type(cmap) == list:\n",
    "            im = ax.imshow(img, cmap=cmap[k])\n",
    "            if type(show_cbar) == list:\n",
    "                if show_cbar[k]:\n",
    "                    fig.subplots_adjust(bottom=0.2)\n",
    "                    cbar_ax = fig.add_axes([0.2, 0.1, 0.6, 0.01])\n",
    "                    fig.colorbar(im, cax=cbar_ax)\n",
    "        else:\n",
    "            im = ax.imshow(img, cmap=cmap)\n",
    "        k = k + 1\n",
    "        ax.set_title(title, fontsize=fontsize)\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "    if type(overlay) == list:\n",
    "        for i, ax in enumerate(axs.flatten()):\n",
    "            if overlay[i] is not None:\n",
    "                im = ax.imshow(overlay[i], alpha=opacity,cmap='jet',vmax=ticks[-1],vmin=ticks[0])\n",
    "                if type(show_cbar_overlay) == list:\n",
    "                    if show_cbar_overlay[i]:\n",
    "                        cbaxes = inset_axes(ax, width=\"30%\", height=\"5%\")\n",
    "                        cbar = fig.colorbar(im,cax=cbaxes, orientation='horizontal',cmap='jet',ticks=ticks)\n",
    "                        cbar.ax.set_xticklabels(labels= ticks,color='yellow',fontsize=fontsize)\n",
    "\n",
    "    if type(text) == list:\n",
    "        for i, ax in enumerate(axs.flatten()):\n",
    "            if text[i] is not None:\n",
    "               im = ax.text(.99, .99, text[i], ha='right', va='top', transform=ax.transAxes,fontsize=fontsize,color='yellow')\n",
    "\n",
    "    if disable_ticks:\n",
    "        for ax in axs.flatten():\n",
    "            ax.get_xaxis().set_ticks([])\n",
    "            ax.get_yaxis().set_ticks([])\n",
    "\n",
    "    return axs\n",
    "\n",
    "\n",
    "# Function for transforming segmentation classes into categorical\n",
    "def one_hot_to_categorical(x, channel_dim: int = 1, background=False):\n",
    "    \"\"\"Converts one-hot encoded predictions to categorical predictions.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor | np.ndarray): One-hot encoded predictions.\n",
    "        channel_dim (int, optional): Channel dimension.\n",
    "            Defaults to ``1`` (i.e. ``(B,C,...)``).\n",
    "        background (bool, optional): If ``True``, assumes index 0 in the\n",
    "            channel dimension is the background.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor | np.ndarray: Categorical array or tensor. If ``background=False``,\n",
    "        the output will be 1-indexed such that ``0`` corresponds to the background.\n",
    "    \"\"\"\n",
    "    is_ndarray = isinstance(x, np.ndarray)\n",
    "    if is_ndarray:\n",
    "        x = torch.as_tensor(x)\n",
    "\n",
    "    if background is not None and background is not False:\n",
    "        out = torch.argmax(x, channel_dim)\n",
    "    else:\n",
    "        out = torch.argmax(x.type(torch.long), dim=channel_dim) + 1\n",
    "        out = torch.where(x.sum(channel_dim) == 0, torch.tensor([0], device=x.device), out)\n",
    "\n",
    "    if is_ndarray:\n",
    "        out = out.numpy()\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def complex_abs(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the absolute value of a complex valued input tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Complex tensor. The last dimension must be of size 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Absolute value of complex tensor.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from atommic.collections.common.parts.utils import complex_abs\n",
    "    >>> import torch\n",
    "    >>> data = torch.tensor([1+1j, 2+2j, 3+3j])\n",
    "    >>> complex_abs(data)\n",
    "    tensor([1.4142, 2.8284, 4.2426])\n",
    "    \"\"\"\n",
    "    if x.shape[-1] != 2:\n",
    "        if torch.is_complex(x):\n",
    "            x = torch.view_as_real(x)\n",
    "        else:\n",
    "            raise ValueError(\"Tensor does not have separate complex dim.\")\n",
    "    return (x ** 2).sum(dim=-1)\n",
    "\n",
    "\n",
    "def check_stacked_complex(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Check if tensor is stacked complex (real & imaginary parts stacked along last dim) and convert it to a combined\n",
    "    complex tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Tensor to check.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Tensor with stacked complex converted to combined complex.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from atommic.collections.common.parts.utils import check_stacked_complex\n",
    "    >>> import torch\n",
    "    >>> data = torch.tensor([1+1j, 2+2j, 3+3j])\n",
    "    >>> data.shape\n",
    "    torch.Size([3])\n",
    "    >>> data = torch.view_as_real(data)\n",
    "    >>> data.shape\n",
    "    >>> check_stacked_complex(data)\n",
    "    tensor([1.+1.j, 2.+2.j, 3.+3.j])\n",
    "    >>> check_stacked_complex(data).shape\n",
    "    torch.Size([3])\n",
    "    >>> data = torch.tensor([1+1j, 2+2j, 3+3j])\n",
    "    >>> data.shape\n",
    "    torch.Size([3])\n",
    "    >>> check_stacked_complex(data)\n",
    "    tensor([1.+1.j, 2.+2.j, 3.+3.j])\n",
    "    >>> check_stacked_complex(data).shape\n",
    "    torch.Size([3])\n",
    "    \"\"\"\n",
    "    return torch.view_as_complex(x) if x.shape[-1] == 2 else x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:52:50.263061Z",
     "end_time": "2024-06-03T10:52:50.351322Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Patient_id =\"MTR_196\" #[\"MTR_052\",\"MTR_066\",\"MTR_120\",\"MTR_196\",\"MTR_227\"]\n",
    "slice = 40\n",
    "echo = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:52:50.303114Z",
     "end_time": "2024-06-03T10:52:50.351929Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:52:50.303162Z",
     "end_time": "2024-06-03T10:53:11.272038Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SENSE_LOGIT_SUM_def/2024-05-23_12-28-07/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_1 = f['segmentation'][()].squeeze()\n",
    "    target_mtlrs_1 = f['target_reconstruction'][()].squeeze()\n",
    "    segmentation_labels_mtlrs_1 = f['target_segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_1 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_1 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SENSE_LOGIT_SUM_def/2024-05-23_12-28-10/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_2 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_2 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_2 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SENSE_LOGIT_SUM_def/2024-05-23_12-28-13/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_3 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_3 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_3 = f['zero_filled'][()].squeeze()\n",
    "inter_pred_mtlrs_1_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_2_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_3_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "mean_logit = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "std_logit = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_std_logit = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_seg_logit = np.zeros((80,5,5,256,256),dtype=np.float32)\n",
    "for i in range(inter_pred_mtlrs_1.shape[2]):\n",
    "    inter_pred_mtlrs_1_norm[:,i] = np.abs(inter_pred_mtlrs_1[:,0,i])/np.max(np.abs(inter_pred_mtlrs_1[:,0,i]))\n",
    "    inter_pred_mtlrs_2_norm[:,i] = np.abs(inter_pred_mtlrs_2[:,0,i])/np.max(np.abs(inter_pred_mtlrs_2[:,0,i]))\n",
    "    inter_pred_mtlrs_3_norm[:,i] = np.abs(inter_pred_mtlrs_3[:,0,i])/np.max(np.abs(inter_pred_mtlrs_3[:,0,i]))\n",
    "    mean_logit[:,i]  = np.mean([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i],inter_pred_mtlrs_3_norm[:,i]],axis=0)\n",
    "    std_logit[:,i]  = np.std([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i],inter_pred_mtlrs_3_norm[:,i]],axis=0)\n",
    "    inter_std_logit[:,i] = np.mean([inter_pred_mtlrs_1[:,1,i].real,inter_pred_mtlrs_2[:,1,i].real,inter_pred_mtlrs_3[:,1,i].real],axis=0)\n",
    "    inter_seg_logit[:,i] = one_hot(torch.argmax(torch.softmax(torch.from_numpy(np.mean([prediction_mtlrs_1[:,i],prediction_mtlrs_2[:,i],prediction_mtlrs_3[:,i]],axis=0)),dim=1),dim=1,keepdim=True),num_classes=segmentation_labels_mtlrs_1.shape[1]).float().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SENSE_NO_MTL_def/2024-05-23_12-22-34/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_1 = f['segmentation'][()].squeeze()\n",
    "    target_mtlrs_1 = f['target_reconstruction'][()].squeeze()\n",
    "    segmentation_labels_mtlrs_1 = f['target_segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_1 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_1 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SENSE_NO_MTL_def/2024-05-23_12-22-37/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_2 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_2 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_2 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SENSE_NO_MTL_def/2024-05-23_12-22-40/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_3 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_3 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_3 = f['zero_filled'][()].squeeze()\n",
    "inter_pred_mtlrs_1_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_2_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_3_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "mean_no_mtl = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "std_no_mtl = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_std_no_mtl = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_seg_no_mtl = np.zeros((80,5,5,256,256),dtype=np.float32)\n",
    "for i in range(inter_pred_mtlrs_1.shape[2]):\n",
    "    inter_pred_mtlrs_1_norm[:,i] = np.abs(inter_pred_mtlrs_1[:,0,i])/np.max(np.abs(inter_pred_mtlrs_1[:,0,i]))\n",
    "    inter_pred_mtlrs_2_norm[:,i] = np.abs(inter_pred_mtlrs_2[:,0,i])/np.max(np.abs(inter_pred_mtlrs_2[:,0,i]))\n",
    "    inter_pred_mtlrs_3_norm[:,i] = np.abs(inter_pred_mtlrs_3[:,0,i])/np.max(np.abs(inter_pred_mtlrs_3[:,0,i]))\n",
    "    mean_no_mtl[:,i]  = np.mean([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i],inter_pred_mtlrs_3_norm[:,i]],axis=0)\n",
    "    std_no_mtl[:,i]  = np.std([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i],inter_pred_mtlrs_3_norm[:,i]],axis=0)\n",
    "    inter_std_no_mtl[:,i] = np.mean([inter_pred_mtlrs_1[:,1,i].real,inter_pred_mtlrs_2[:,1,i].real,inter_pred_mtlrs_3[:,1,i].real],axis=0)\n",
    "    inter_seg_no_mtl[:,i] = one_hot(torch.argmax(torch.softmax(torch.from_numpy(np.mean([prediction_mtlrs_1[:,i],prediction_mtlrs_2[:,i],prediction_mtlrs_3[:,i]],axis=0)),dim=1),dim=1,keepdim=True),num_classes=segmentation_labels_mtlrs_1.shape[1]).float().numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:53:11.311055Z",
     "end_time": "2024-06-03T10:53:33.747380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_SASG_def/2024-05-28_20-53-08/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_1 = f['segmentation'][()].squeeze()\n",
    "    target_mtlrs_1 = f['target_reconstruction'][()].squeeze()\n",
    "    segmentation_labels_mtlrs_1 = f['target_segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_1 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_1 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_SASG_def/2024-05-28_20-53-11/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_2 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_2 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_2 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_SASG_def/2024-05-29_11-48-43/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_3 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_3 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_3 = f['zero_filled'][()].squeeze()\n",
    "inter_pred_mtlrs_1_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_2_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_3_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "mean_sasg = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "std_sasg = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_std_sasg = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_seg_sasg = np.zeros((80,5,5,256,256),dtype=np.float32)\n",
    "for i in range(inter_pred_mtlrs_1.shape[2]):\n",
    "    inter_pred_mtlrs_1_norm[:,i] = np.abs(inter_pred_mtlrs_1[:,0,i])/np.max(np.abs(inter_pred_mtlrs_1[:,0,i]))\n",
    "    inter_pred_mtlrs_2_norm[:,i] = np.abs(inter_pred_mtlrs_2[:,0,i])/np.max(np.abs(inter_pred_mtlrs_2[:,0,i]))\n",
    "    inter_pred_mtlrs_3_norm[:,i] = np.abs(inter_pred_mtlrs_3[:,0,i])/np.max(np.abs(inter_pred_mtlrs_3[:,0,i]))\n",
    "    mean_sasg[:,i]  = np.mean([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i],inter_pred_mtlrs_3_norm[:,i]],axis=0)\n",
    "    std_sasg[:,i]  = np.std([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i],inter_pred_mtlrs_3_norm[:,i]],axis=0)\n",
    "    inter_std_sasg[:,i] = np.mean([inter_pred_mtlrs_1[:,1,i].real,inter_pred_mtlrs_2[:,1,i].real,inter_pred_mtlrs_3[:,1,i].real],axis=0)\n",
    "    inter_seg_sasg[:,i] = one_hot(torch.argmax(torch.softmax(torch.from_numpy(np.mean([prediction_mtlrs_1[:,i],prediction_mtlrs_2[:,i],prediction_mtlrs_3[:,i]],axis=0)),dim=1),dim=1,keepdim=True),num_classes=segmentation_labels_mtlrs_1.shape[1]).float().numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:53:33.758394Z",
     "end_time": "2024-06-03T10:53:57.804749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_TAM_def/2024-05-29_15-20-28/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_1 = f['segmentation'][()].squeeze()\n",
    "    target_mtlrs_1 = f['target_reconstruction'][()].squeeze()\n",
    "    segmentation_labels_mtlrs_1 = f['target_segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_1 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_1 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_TAM_def/2024-05-29_15-20-31/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_2 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_2 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_2 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_TAM_def/2024-05-31_08-40-15/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_3 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_3 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_3 = f['zero_filled'][()].squeeze()\n",
    "inter_pred_mtlrs_1_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_2_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_3_norm =np.zeros((80,5,2,256,256))\n",
    "mean_softmax_tam = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "std_softmax_tam  = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_std_softmax_tam  = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_seg_softmax_tam = np.zeros((80,5,5,256,256),dtype=np.float32)\n",
    "for i in range(inter_pred_mtlrs_1.shape[2]):\n",
    "    inter_pred_mtlrs_1_norm[:,i] = np.abs(inter_pred_mtlrs_1[:,0,i])/np.max(np.abs(inter_pred_mtlrs_1[:,0,i]))\n",
    "    inter_pred_mtlrs_2_norm[:,i] = np.abs(inter_pred_mtlrs_2[:,0,i])/np.max(np.abs(inter_pred_mtlrs_2[:,0,i]))\n",
    "    inter_pred_mtlrs_3_norm[:,i] = np.abs(inter_pred_mtlrs_3[:,0,i])/np.max(np.abs(inter_pred_mtlrs_3[:,0,i]))\n",
    "    mean_softmax_tam[:,i]  = np.mean([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i]],axis=0)\n",
    "    std_softmax_tam[:,i]  = np.std([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i]],axis=0)\n",
    "    inter_std_softmax_tam[:,i] = np.mean([inter_pred_mtlrs_1[:,1,i].real,inter_pred_mtlrs_2[:,1,i].real,inter_pred_mtlrs_3[:,1,i].real],axis=0)\n",
    "    inter_seg_softmax_tam[:,i] = one_hot(torch.argmax(torch.softmax(torch.from_numpy(np.mean([prediction_mtlrs_1[:,i],prediction_mtlrs_2[:,i],prediction_mtlrs_3[:,i]],axis=0)),dim=1),dim=1,keepdim=True),num_classes=segmentation_labels_mtlrs_1.shape[1]).float().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:53:57.843914Z",
     "end_time": "2024-06-03T10:54:20.764492Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_SUM_def/2024-05-30_10-14-44/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_1 = f['segmentation'][()].squeeze()\n",
    "    target_mtlrs_1 = f['target_reconstruction'][()].squeeze()\n",
    "    segmentation_labels_mtlrs_1 = f['target_segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_1 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_1 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_SUM_def/2024-05-30_10-14-41/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_2 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_2 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_2 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_SOFTMAX_SUM_def/2024-05-29_11-49-51/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_3 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_3 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_3 = f['zero_filled'][()].squeeze()\n",
    "inter_pred_mtlrs_1_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_2_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_3_norm =np.zeros((80,5,2,256,256))\n",
    "mean_softmax_sum = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "std_softmax_sum = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_std_softmax_sum  = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_seg_softmax_sum = np.zeros((80,5,5,256,256),dtype=np.float32)\n",
    "for i in range(inter_pred_mtlrs_1.shape[2]):\n",
    "    inter_pred_mtlrs_1_norm[:,i] = np.abs(inter_pred_mtlrs_1[:,0,i])/np.max(np.abs(inter_pred_mtlrs_1[:,0,i]))\n",
    "    inter_pred_mtlrs_2_norm[:,i] = np.abs(inter_pred_mtlrs_2[:,0,i])/np.max(np.abs(inter_pred_mtlrs_2[:,0,i]))\n",
    "    inter_pred_mtlrs_3_norm[:,i] = np.abs(inter_pred_mtlrs_3[:,0,i])/np.max(np.abs(inter_pred_mtlrs_3[:,0,i]))\n",
    "    mean_softmax_sum[:,i]  = np.mean([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i]],axis=0)\n",
    "    std_softmax_sum[:,i]  = np.std([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i]],axis=0)\n",
    "    inter_std_softmax_sum[:,i] = np.mean([inter_pred_mtlrs_1[:,1,i].real,inter_pred_mtlrs_2[:,1,i].real,inter_pred_mtlrs_3[:,1,i].real],axis=0)\n",
    "    inter_seg_softmax_sum[:,i] = one_hot(torch.argmax(torch.softmax(torch.from_numpy(np.mean([prediction_mtlrs_1[:,i],prediction_mtlrs_2[:,i],prediction_mtlrs_3[:,i]],axis=0)),dim=1),dim=1,keepdim=True),num_classes=segmentation_labels_mtlrs_1.shape[1]).float().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:54:20.764131Z",
     "end_time": "2024-06-03T10:54:41.461558Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_LOGIT_TAM_def/2024-05-31_08-42-02/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_1 = f['segmentation'][()].squeeze()\n",
    "    target_mtlrs_1 = f['target_reconstruction'][()].squeeze()\n",
    "    segmentation_labels_mtlrs_1 = f['target_segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_1 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_1 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_LOGIT_TAM_def/2024-05-31_08-42-05/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_2 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_2 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_2 = f['zero_filled'][()].squeeze()\n",
    "\n",
    "\n",
    "fname = f'/data/projects/utwente/recon/SKM-TEA/v1-release/predictions/MTLRS_SENSE/predictions_8x/MTLRS_SKMTEA_LOGIT_TAM_def/2024-05-31_08-42-08/predictions/{Patient_id}.h5'\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    prediction_mtlrs_3 = f['segmentation'][()].squeeze()\n",
    "    inter_pred_mtlrs_3 = f['intermediate_reconstruction'][()].squeeze()\n",
    "    zero_filled_mtlrs_3 = f['zero_filled'][()].squeeze()\n",
    "inter_pred_mtlrs_1_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_2_norm =np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_pred_mtlrs_3_norm =np.zeros((80,5,2,256,256))\n",
    "mean_logit_tam = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "std_logit_tam  = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_std_logit_tam  = np.zeros((80,5,2,256,256),dtype=np.float32)\n",
    "inter_seg_logit_tam = np.zeros((80,5,5,256,256),dtype=np.float32)\n",
    "for i in range(inter_pred_mtlrs_1.shape[2]):\n",
    "    inter_pred_mtlrs_1_norm[:,i] = np.abs(inter_pred_mtlrs_1[:,0,i])/np.max(np.abs(inter_pred_mtlrs_1[:,0,i]))\n",
    "    inter_pred_mtlrs_2_norm[:,i] = np.abs(inter_pred_mtlrs_2[:,0,i])/np.max(np.abs(inter_pred_mtlrs_2[:,0,i]))\n",
    "    inter_pred_mtlrs_3_norm[:,i] = np.abs(inter_pred_mtlrs_3[:,0,i])/np.max(np.abs(inter_pred_mtlrs_3[:,0,i]))\n",
    "    mean_logit_tam[:,i]  = np.mean([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i]],axis=0)\n",
    "    std_logit_tam[:,i]  = np.std([inter_pred_mtlrs_1_norm[:,i],inter_pred_mtlrs_2_norm[:,i]],axis=0)\n",
    "    inter_std_logit_tam[:,i] = np.mean([inter_pred_mtlrs_1[:,1,i].real,inter_pred_mtlrs_2[:,1,i].real,inter_pred_mtlrs_3[:,1,i].real],axis=0)\n",
    "    inter_seg_logit_tam[:,i] = one_hot(torch.argmax(torch.softmax(torch.from_numpy(np.mean([prediction_mtlrs_1[:,i],prediction_mtlrs_2[:,i],prediction_mtlrs_3[:,i]],axis=0)),dim=1),dim=1,keepdim=True),num_classes=segmentation_labels_mtlrs_1.shape[1]).float().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:54:41.461061Z",
     "end_time": "2024-06-03T10:54:59.721461Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(mean_logit.dtype)\n",
    "zero_filled_mtlrs_1 = np.abs(zero_filled_mtlrs_1)/np.max(np.abs(zero_filled_mtlrs_1))\n",
    "target_mtlrs_1 = np.abs(target_mtlrs_1)/np.max(np.abs(target_mtlrs_1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:54:59.725451Z",
     "end_time": "2024-06-03T10:54:59.975052Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hsize = 10\n",
    "wsize = hsize / target_mtlrs_1.shape[2] * target_mtlrs_1.shape[3]\n",
    "max_value = max(np.max(mean_no_mtl[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_no_mtl[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_no_mtl[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_no_mtl[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_no_mtl[slice,4,echo],maxval=max_value)\n",
    "fig, axs = plt.subplots(6, 8, figsize=(8 * wsize, 6 * hsize))\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_no_mtl[slice,0,echo],mean_no_mtl[slice,1,echo],mean_no_mtl[slice,2,echo],mean_no_mtl[slice,3,echo],mean_no_mtl[slice,4,echo],mean_no_mtl[slice,4,echo],target_mtlrs_1[slice,echo]],titles=[\"Zero Filled\",\"Prediction C1\",\"Prediction C2\",\"Prediction C3\",\"Prediction C4\",\"Prediction C5\",\"Final mean prediction\",\"Target\"],axs=axs[0],overlay=[None,std_no_mtl[slice,0,echo],std_no_mtl[slice,1,echo],std_no_mtl[slice,2,echo],std_no_mtl[slice,3,echo],std_no_mtl[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.04,0.08])\n",
    "axs[0,0].set_ylabel(\"NO MTL\", fontsize=40)\n",
    "max_value = max(np.max(mean_logit[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_logit[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_logit[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_logit[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_logit[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_logit[slice,0,echo],mean_logit[slice,1,echo],mean_logit[slice,2,echo],mean_logit[slice,3,echo],mean_logit[slice,4,echo],mean_logit[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[1],overlay=[None,std_logit[slice,0,echo],std_logit[slice,1,echo],std_logit[slice,2,echo],std_logit[slice,3,echo],std_logit[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.04,0.08])\n",
    "axs[1,0].set_ylabel(\"SUM LOGIT\", fontsize=40)\n",
    "max_value = max(np.max(mean_softmax_sum[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_softmax_sum[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_softmax_sum[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_softmax_sum[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_softmax_sum[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_softmax_sum[slice,0,echo],mean_softmax_sum[slice,1,echo],mean_softmax_sum[slice,2,echo],mean_softmax_sum[slice,3,echo],mean_softmax_sum[slice,4,echo],mean_softmax_sum[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[2],overlay=[None,std_softmax_sum[slice,0,echo],std_softmax_sum[slice,1,echo],std_softmax_sum[slice,2,echo],std_softmax_sum[slice,3,echo],std_softmax_sum[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.04,0.08])\n",
    "axs[2,0].set_ylabel(\"SUM SOFTMAX\", fontsize=40)\n",
    "max_value = max(np.max(mean_sasg[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_sasg[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_sasg[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_sasg[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_sasg[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_sasg[slice,0,echo],mean_sasg[slice,1,echo],mean_sasg[slice,2,echo],mean_sasg[slice,3,echo],mean_sasg[slice,4,echo],mean_sasg[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[3],overlay=[None,std_sasg[slice,0,echo],std_sasg[slice,1,echo],std_sasg[slice,2,echo],std_sasg[slice,3,echo],std_sasg[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.04,0.08])\n",
    "axs[3,0].set_ylabel(\"SASG\", fontsize=40)\n",
    "max_value = max(np.max(mean_logit_tam[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_logit_tam[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_logit_tam[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_logit_tam[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_logit_tam[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_logit_tam[slice,0,echo],mean_logit_tam[slice,1,echo],mean_logit_tam[slice,2,echo],mean_logit_tam[slice,3,echo],mean_logit_tam[slice,4,echo],mean_logit_tam[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[4],overlay=[None,std_logit_tam[slice,0,echo],std_logit_tam[slice,1,echo],std_logit_tam[slice,2,echo],std_logit_tam[slice,3,echo],std_logit_tam[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.04,0.08])\n",
    "axs[4,0].set_ylabel(\"LOGIT TAM\", fontsize=40)\n",
    "max_value = max(np.max(mean_softmax_tam[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_softmax_tam[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_softmax_tam[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_softmax_tam[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_softmax_tam[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_softmax_tam[slice,0,echo],mean_softmax_tam[slice,1,echo],mean_softmax_tam[slice,2,echo],mean_softmax_tam[slice,3,echo],mean_softmax_tam[slice,4,echo],mean_softmax_tam[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[5],overlay=[None,std_softmax_tam[slice,0,echo],std_softmax_tam[slice,1,echo],std_softmax_tam[slice,2,echo],std_softmax_tam[slice,3,echo],std_softmax_tam[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.04,0.08])\n",
    "axs[5,0].set_ylabel(\"SOFTMAX TAM\", fontsize=40)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(f\"/scratch/tmpaquaij/Figures/Intermediate_predictions_UQ_{Patient_id}_Echo:{str(echo)}_slice:{str(slice)}.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:55:00.011762Z",
     "end_time": "2024-06-03T10:55:19.964479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "hsize = 10\n",
    "wsize = hsize / target_mtlrs_1.shape[2] * target_mtlrs_1.shape[3]\n",
    "max_value = max(np.max(mean_no_mtl[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_no_mtl[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_no_mtl[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_no_mtl[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_no_mtl[slice,4,echo],maxval=max_value)\n",
    "fig, axs = plt.subplots(6, 8, figsize=(8 * wsize, 6 * hsize))\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_no_mtl[slice,0,echo],mean_no_mtl[slice,1,echo],mean_no_mtl[slice,2,echo],mean_no_mtl[slice,3,echo],mean_no_mtl[slice,4,echo],mean_no_mtl[slice,4,echo],target_mtlrs_1[slice,echo]],titles=[\"Zero Filled\",\"Prediction C1\",\"Prediction C2\",\"Prediction C3\",\"Prediction C4\",\"Prediction C5\",\"Final mean prediction\",\"Target\"],axs=axs[0],overlay=[None,inter_std_no_mtl[slice,0,echo],inter_std_no_mtl[slice,1,echo],inter_std_no_mtl[slice,2,echo],inter_std_no_mtl[slice,3,echo],inter_std_no_mtl[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.02,0.04])\n",
    "axs[0,0].set_ylabel(\"NO MTL\", fontsize=40)\n",
    "max_value = max(np.max(mean_logit[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_logit[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_logit[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_logit[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_logit[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_logit[slice,0,echo],mean_logit[slice,1,echo],mean_logit[slice,2,echo],mean_logit[slice,3,echo],mean_logit[slice,4,echo],mean_logit[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[1],overlay=[None,inter_std_logit[slice,0,echo],inter_std_logit[slice,1,echo],inter_std_logit[slice,2,echo],inter_std_logit[slice,3,echo],inter_std_logit[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.02,0.04])\n",
    "axs[1,0].set_ylabel(\"SUM LOGIT\", fontsize=40)\n",
    "max_value = max(np.max(mean_softmax_sum[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_softmax_sum[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_softmax_sum[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_softmax_sum[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_softmax_sum[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_softmax_sum[slice,0,echo],mean_softmax_sum[slice,1,echo],mean_softmax_sum[slice,2,echo],mean_softmax_sum[slice,3,echo],mean_softmax_sum[slice,4,echo],mean_softmax_sum[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[2],overlay=[None,inter_std_softmax_sum[slice,0,echo],inter_std_softmax_sum[slice,1,echo],inter_std_softmax_sum[slice,2,echo],inter_std_softmax_sum[slice,3,echo],inter_std_softmax_sum[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.02,0.04])\n",
    "axs[2,0].set_ylabel(\"SUM SOFTMAX\", fontsize=40)\n",
    "max_value = max(np.max(mean_sasg[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_sasg[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_sasg[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_sasg[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_sasg[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_sasg[slice,0,echo],mean_sasg[slice,1,echo],mean_sasg[slice,2,echo],mean_sasg[slice,3,echo],mean_sasg[slice,4,echo],mean_sasg[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[3],overlay=[None,inter_std_sasg[slice,0,echo],inter_std_sasg[slice,1,echo],inter_std_sasg[slice,2,echo],inter_std_sasg[slice,3,echo],inter_std_sasg[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.02,0.04])\n",
    "axs[3,0].set_ylabel(\"SASG\", fontsize=40)\n",
    "max_value = max(np.max(mean_logit_tam[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_logit_tam[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_logit_tam[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_logit_tam[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_logit_tam[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_logit_tam[slice,0,echo],mean_logit_tam[slice,1,echo],mean_logit_tam[slice,2,echo],mean_logit_tam[slice,3,echo],mean_logit_tam[slice,4,echo],mean_logit_tam[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[4],overlay=[None,inter_std_logit_tam[slice,0,echo],inter_std_logit_tam[slice,1,echo],inter_std_logit_tam[slice,2,echo],inter_std_logit_tam[slice,3,echo],inter_std_logit_tam[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.02,0.04])\n",
    "axs[4,0].set_ylabel(\"LOGIT TAM\", fontsize=40)\n",
    "max_value = max(np.max(mean_softmax_tam[slice,4,echo]),np.max(target_mtlrs_1[slice,echo]))\n",
    "ssim_score =ssim(target_mtlrs_1[slice,echo],mean_softmax_tam[slice,4,echo],maxval=max_value)\n",
    "psnr_score =psnr(target_mtlrs_1[slice,echo],mean_softmax_tam[slice,4,echo],maxval=max_value)\n",
    "haarpsi_score =haarpsi3d(target_mtlrs_1[slice,echo],mean_softmax_tam[slice,4,echo],maxval=max_value)\n",
    "vsi_score =vsi3d(target_mtlrs_1[slice,echo],mean_softmax_tam[slice,4,echo],maxval=max_value)\n",
    "plot_images([zero_filled_mtlrs_1[slice,echo],mean_softmax_tam[slice,0,echo],mean_softmax_tam[slice,1,echo],mean_softmax_tam[slice,2,echo],mean_softmax_tam[slice,3,echo],mean_softmax_tam[slice,4,echo],mean_softmax_tam[slice,4,echo],target_mtlrs_1[slice,echo]],axs=axs[5],overlay=[None,inter_std_softmax_tam[slice,0,echo],inter_std_softmax_tam[slice,1,echo],inter_std_softmax_tam[slice,2,echo],inter_std_softmax_tam[slice,3,echo],inter_std_softmax_tam[slice,4,echo],None,None],show_cbar_overlay=[False,True,True,True,True,True,False,False],fontsize =40,text=[None,None,None,None,None,None,f'SSIM: {round(ssim_score,3)} \\n PSNR: {round(psnr_score,3)} \\n HaarPSI: {round(haarpsi_score,3)} \\n VSI: {round(vsi_score,3)}',f'Patient: {Patient_id}'],ticks=[0.0,0.02,0.04])\n",
    "axs[5,0].set_ylabel(\"SOFTMAX TAM\", fontsize=40)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(f\"/scratch/tmpaquaij/Figures/Intermediate_predictions_inter_UQ_{Patient_id}_echo:{str(echo)}_slice:{str(slice)}.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:55:19.964170Z",
     "end_time": "2024-06-03T10:55:36.646262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hsize = 10\n",
    "wsize = hsize / target_mtlrs_1.shape[2] * target_mtlrs_1.shape[3]\n",
    "dice_score =dice_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_no_mtl[slice,1:,4])\n",
    "assd_score =float(asd(segmentation_labels_mtlrs_1[slice,1:],inter_seg_no_mtl[slice,1:,4],voxelspacing=[0.4,0.312/2]))\n",
    "f1_score =float(f1_per_class_metric(segmentation_labels_mtlrs_1[slice,1:,],inter_seg_no_mtl[slice,1:,4]))\n",
    "HD95_score =float(hausdorff_distance_95_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_no_mtl[slice,1:,4]))\n",
    "IOU_score =float(iou_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_no_mtl[slice,1:,4]))\n",
    "\n",
    "inter_seg_no_mtl_plot = torch.argmax(torch.from_numpy(inter_seg_no_mtl),dim=2)\n",
    "segmentation_labels_mtlrs_1_plot = torch.argmax(torch.from_numpy(segmentation_labels_mtlrs_1),dim=1)\n",
    "\n",
    "fig, axs = plt.subplots(6, 6, figsize=(6 * wsize, 6 * hsize))\n",
    "plot_images([inter_seg_no_mtl_plot[slice,0],inter_seg_no_mtl_plot[slice,1],inter_seg_no_mtl_plot[slice,2],inter_seg_no_mtl_plot[slice,3],inter_seg_no_mtl_plot[slice,4],segmentation_labels_mtlrs_1_plot[slice]],titles=[\"Segmentation C1\",\"Segmentation C2\",\"Segmentation C3\",\"Segmentation C4\",\"Segmentation C5\",\"Target\"],axs=axs[0],fontsize =40,cmap=['viridis','viridis','viridis','viridis','viridis','viridis','viridis'],text=[None,None,None,None,f'DICE: {round(dice_score,3)} \\n ASSD: {round(assd_score,3)} mm \\n F1: {round(f1_score,3)} \\n HD95: {round(HD95_score,3)} \\n IoU: {round(IOU_score,3)}',None])\n",
    "axs[0][0].set_ylabel(\"NO MTL\", fontsize=40)\n",
    "dice_score =dice_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_logit[slice,1:,4])\n",
    "assd_score =float(asd(segmentation_labels_mtlrs_1[slice,1:],inter_seg_logit[slice,1:,4],voxelspacing=[0.4,0.312/2]))\n",
    "f1_score =float(f1_per_class_metric(segmentation_labels_mtlrs_1[slice,1:,],inter_seg_logit[slice,1:,4]))\n",
    "HD95_score =float(hausdorff_distance_95_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_logit[slice,1:,4]))\n",
    "IOU_score =float(iou_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_logit[slice,1:,4]))\n",
    "\n",
    "inter_seg_logit_plot = torch.argmax(torch.from_numpy(inter_seg_logit),dim=2)\n",
    "plot_images([inter_seg_logit_plot[slice,0],inter_seg_logit_plot[slice,1],inter_seg_logit_plot[slice,2],inter_seg_logit_plot[slice,3],inter_seg_logit_plot[slice,4],segmentation_labels_mtlrs_1_plot[slice]],axs=axs[1],fontsize =40,cmap=['viridis','viridis','viridis','viridis','viridis','viridis','viridis'],text=[None,None,None,None,f'DICE: {round(dice_score,3)} \\n ASSD: {round(assd_score,3)} mm \\n F1: {round(f1_score,3)} \\n HD95: {round(HD95_score,3)} \\n IoU: {round(IOU_score,3)}',f'Patient: {Patient_id}'])\n",
    "axs[1,0].set_ylabel(\"SUM LOGIT\", fontsize=40)\n",
    "dice_score =dice_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_softmax_sum[slice,1:,4])\n",
    "assd_score =float(asd(segmentation_labels_mtlrs_1[slice,1:],inter_seg_softmax_sum[slice,1:,4],voxelspacing=[0.4,0.312/2]))\n",
    "f1_score =float(f1_per_class_metric(segmentation_labels_mtlrs_1[slice,1:,],inter_seg_softmax_sum[slice,1:,4]))\n",
    "HD95_score =float(hausdorff_distance_95_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_softmax_sum[slice,1:,4]))\n",
    "IOU_score =float(iou_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_softmax_sum[slice,1:,4]))\n",
    "\n",
    "inter_seg_softmax_sum_plot = torch.argmax(torch.from_numpy(inter_seg_softmax_sum),dim=2)\n",
    "plot_images([inter_seg_softmax_sum_plot[slice,0],inter_seg_softmax_sum_plot[slice,1],inter_seg_softmax_sum_plot[slice,2],inter_seg_softmax_sum_plot[slice,3],inter_seg_softmax_sum_plot[slice,4],segmentation_labels_mtlrs_1_plot[slice]],axs=axs[2],fontsize =40,cmap=['viridis','viridis','viridis','viridis','viridis','viridis','viridis'],text=[None,None,None,None,f'DICE: {round(dice_score,3)} \\n ASSD: {round(assd_score,3)} mm \\n F1: {round(f1_score,3)} \\n HD95: {round(HD95_score,3)} \\n IoU: {round(IOU_score,3)}',f'Patient: {Patient_id}'])\n",
    "axs[2,0].set_ylabel(\"SUM SOFTMAX\", fontsize=40)\n",
    "dice_score =dice_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_sasg[slice,1:,4])\n",
    "assd_score =float(asd(segmentation_labels_mtlrs_1[slice,1:],inter_seg_sasg[slice,1:,4],voxelspacing=[0.4,0.312/2]))\n",
    "f1_score =float(f1_per_class_metric(segmentation_labels_mtlrs_1[slice,1:,],inter_seg_sasg[slice,1:,4]))\n",
    "HD95_score =float(hausdorff_distance_95_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_sasg[slice,1:,4]))\n",
    "IOU_score =float(iou_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_sasg[slice,1:,4]))\n",
    "\n",
    "inter_seg_sasg_plot = torch.argmax(torch.from_numpy(inter_seg_sasg),dim=2)\n",
    "plot_images([inter_seg_sasg_plot[slice,0],inter_seg_sasg_plot[slice,0],inter_seg_sasg_plot[slice,0],inter_seg_sasg_plot[slice,0],inter_seg_sasg_plot[slice,0],segmentation_labels_mtlrs_1_plot[slice]],axs=axs[3],fontsize =40,cmap=['viridis','viridis','viridis','viridis','viridis','viridis','viridis'],text=[None,None,None,None,f'DICE: {round(dice_score,3)} \\n ASSD: {round(assd_score,3)} mm \\n F1: {round(f1_score,3)} \\n HD95: {round(HD95_score,3)} \\n IoU: {round(IOU_score,3)}',,f'Patient: {Patient_id}'])\n",
    "axs[3,0].set_ylabel(\"SASG\", fontsize=40)\n",
    "dice_score =dice_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_logit_tam[slice,1:,4])\n",
    "assd_score =float(asd(segmentation_labels_mtlrs_1[slice,1:],inter_seg_logit_tam[slice,1:,4],voxelspacing=[0.4,0.312/2]))\n",
    "f1_score =float(f1_per_class_metric(segmentation_labels_mtlrs_1[slice,1:,],inter_seg_logit_tam[slice,1:,4]))\n",
    "HD95_score =float(hausdorff_distance_95_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_logit_tam[slice,1:,4]))\n",
    "IOU_score =float(iou_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_logit_tam[slice,1:,4]))\n",
    "\n",
    "inter_seg_logit_tam_plot = torch.argmax(torch.from_numpy(inter_seg_logit_tam),dim=2)\n",
    "plot_images([inter_seg_logit_tam_plot[slice,0],inter_seg_logit_tam_plot[slice,1],inter_seg_logit_tam_plot[slice,2],inter_seg_logit_tam_plot[slice,3],inter_seg_logit_tam_plot[slice,4],segmentation_labels_mtlrs_1_plot[slice]],axs=axs[4],fontsize =40,cmap=['viridis','viridis','viridis','viridis','viridis','viridis','viridis'],text=[None,None,None,None,f'DICE: {round(dice_score,3)} \\n ASSD: {round(assd_score,3)} mm \\n F1: {round(f1_score,3)} \\n HD95: {round(HD95_score,3)} \\n IoU: {round(IOU_score,3)}',,f'Patient: {Patient_id}'])\n",
    "\n",
    "axs[4,0].set_ylabel(\"LOGIT TAM\", fontsize=40)\n",
    "dice_score =dice_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_softmax_tam[slice,1:,4])\n",
    "assd_score =float(asd(segmentation_labels_mtlrs_1[slice,1:],inter_seg_softmax_tam[slice,1:,4],voxelspacing=[0.4,0.312/2]))\n",
    "f1_score =float(f1_per_class_metric(segmentation_labels_mtlrs_1[slice,1:,],inter_seg_softmax_tam[slice,1:,4]))\n",
    "HD95_score =float(hausdorff_distance_95_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_softmax_tam[slice,1:,4]))\n",
    "IOU_score =float(iou_metric(segmentation_labels_mtlrs_1[slice,1:],inter_seg_softmax_tam[slice,1:,4]))\n",
    "inter_seg_softmax_tam_plot = torch.argmax(torch.from_numpy(inter_seg_softmax_tam),dim=2)\n",
    "plot_images([inter_seg_softmax_tam_plot[slice,0],inter_seg_softmax_tam_plot[slice,1],inter_seg_softmax_tam_plot[slice,2],inter_seg_softmax_tam_plot[slice,3],inter_seg_softmax_tam_plot[slice,4],segmentation_labels_mtlrs_1_plot[slice]],axs=axs[5],fontsize =40,cmap=['viridis','viridis','viridis','viridis','viridis','viridis','viridis'],text=[None,None,None,None,f'DICE: {round(dice_score,3)} \\n ASSD: {round(assd_score,3)} mm \\n F1: {round(f1_score,3)} \\n HD95: {round(HD95_score,3)} \\n IoU: {round(IOU_score,3)}',f'Patient: {Patient_id}'])\n",
    "axs[5,0].set_ylabel(\"SOFTMAX TAM\", fontsize=40)\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(f\"/scratch/tmpaquaij/Figures/Intermediate_segmentation_inter_UQ_{Patient_id}_echo:{str(echo)}_slice:{str(slice)}.png\")\n",
    "\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:55:36.665255Z",
     "end_time": "2024-06-03T10:56:08.725210Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T10:56:08.725002Z",
     "end_time": "2024-06-03T10:56:08.725517Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
