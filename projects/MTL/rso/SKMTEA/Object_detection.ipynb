{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-02-22T11:57:18.879374Z",
     "end_time": "2024-02-22T11:57:25.191587Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from typing import Union, Sequence\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import h5py\n",
    "from skimage.color import label2rgb\n",
    "import json\n",
    "import ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Function for plotting MRI scans\n",
    "\n",
    "\n",
    "def get_scaled_image(\n",
    "        x: Union[torch.Tensor, np.ndarray], percentile=0.99, clip=False\n",
    "):\n",
    "    \"\"\"Scales image by intensity percentile (and optionally clips to [0, 1]).\n",
    "\n",
    "    Args:\n",
    "      x (torch.Tensor | np.ndarray): The image to process.\n",
    "      percentile (float): The percentile of magnitude to scale by.\n",
    "      clip (bool): If True, clip values between [0, 1]\n",
    "\n",
    "    Returns:\n",
    "      torch.Tensor | np.ndarray: The scaled image.\n",
    "    \"\"\"\n",
    "    is_numpy = isinstance(x, np.ndarray)\n",
    "    if is_numpy:\n",
    "        x = torch.as_tensor(x)\n",
    "\n",
    "    scale_factor = torch.quantile(x, percentile)\n",
    "    x = x / scale_factor\n",
    "    if clip:\n",
    "        x = torch.clip(x, 0, 1)\n",
    "\n",
    "    if is_numpy:\n",
    "        x = x.numpy()\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def plot_images(\n",
    "        images, processor=None, disable_ticks=True, titles: Sequence[str] = None,\n",
    "        ylabel: str = None, xlabels: Sequence[str] = None, cmap: str = \"gray\",\n",
    "        show_cbar: bool = False, overlay=None, opacity: float = 0.3,\n",
    "        hsize=5, wsize=5, axs=None, fontsize=20\n",
    "):\n",
    "    \"\"\"Plot multiple images in a single row.\n",
    "\n",
    "    Add an overlay with the `overlay=` argument.\n",
    "    Add a colorbar with `show_cbar=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_default_values(x, default=\"\"):\n",
    "        if x is None:\n",
    "            return [default] * len(images)\n",
    "        return x\n",
    "\n",
    "    titles = get_default_values(titles)\n",
    "    ylabels = get_default_values(images)\n",
    "    xlabels = get_default_values(xlabels)\n",
    "\n",
    "    N = len(images)\n",
    "    if axs is None:\n",
    "        fig, axs = plt.subplots(1, N, figsize=(wsize * N, hsize))\n",
    "    else:\n",
    "        assert len(axs) >= N\n",
    "        fig = axs.flatten()[0].get_figure()\n",
    "    k = 0\n",
    "    for ax, img, title, xlabel in zip(axs, images, titles, xlabels):\n",
    "        if processor is not None:\n",
    "            img = processor(img)\n",
    "        if type(cmap) == list:\n",
    "            im = ax.imshow(img, cmap=cmap[k])\n",
    "            if type(show_cbar) == list:\n",
    "                if show_cbar[k]:\n",
    "                    fig.subplots_adjust(right=0.8)\n",
    "                    cbar_ax = fig.add_axes([0.85, 0.2, 0.01, 0.60])\n",
    "                    fig.colorbar(im, cax=cbar_ax)\n",
    "        else:\n",
    "            im = ax.imshow(img, cmap=cmap)\n",
    "        k = k + 1\n",
    "        ax.set_title(title, fontsize=fontsize)\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "    if type(overlay) == list:\n",
    "        for i, ax in enumerate(axs.flatten()):\n",
    "            if overlay[i] is not None:\n",
    "                im = ax.imshow(overlay[i], alpha=opacity)\n",
    "\n",
    "    if disable_ticks:\n",
    "        for ax in axs.flatten():\n",
    "            ax.get_xaxis().set_ticks([])\n",
    "            ax.get_yaxis().set_ticks([])\n",
    "\n",
    "    return axs\n",
    "\n",
    "\n",
    "# Function for transforming segmentation classes into one hot\n",
    "def categorical_to_one_hot(x, channel_dim: int = 1, background=0, num_categories=None, dtype=None):\n",
    "    \"\"\"Converts categorical predictions to one-hot encoded predictions.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor | np.ndarray): Categorical array or tensor.\n",
    "        channel_dim (int, optional): Channel dimension for output tensor.\n",
    "        background (int | NoneType, optional): The numerical label of the\n",
    "            background category. If ``None``, assumes that the background is\n",
    "            a class that should be one-hot encoded.\n",
    "        num_categories (int, optional): Number of categories (excluding background).\n",
    "            Defaults to the ``max(x) + 1``.\n",
    "        dtype (type, optional): Data type of the output.\n",
    "            Defaults to boolean (``torch.bool`` or ``np.bool``).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor | np.ndarray: One-hot encoded predictions.\n",
    "    \"\"\"\n",
    "    is_ndarray = isinstance(x, np.ndarray)\n",
    "    if is_ndarray:\n",
    "        x = torch.from_numpy(x)\n",
    "\n",
    "    if num_categories is None:\n",
    "        num_categories = torch.max(x).type(torch.long).cpu().item()\n",
    "    num_categories += 1\n",
    "\n",
    "    shape = x.shape\n",
    "    out_shape = (num_categories,) + shape\n",
    "\n",
    "    if dtype is None:\n",
    "        dtype = torch.bool\n",
    "    default_value = True if dtype == torch.bool else 1\n",
    "    if x.dtype != torch.long:\n",
    "        x = x.type(torch.long)\n",
    "\n",
    "    out = torch.zeros(out_shape, dtype=dtype, device=x.device)\n",
    "    out.scatter_(0, x.reshape((1,) + x.shape), default_value)\n",
    "    if background is not None:\n",
    "        out = torch.cat([out[0:background], out[background + 1:]], dim=0)\n",
    "    if channel_dim != 0:\n",
    "        if channel_dim < 0:\n",
    "            channel_dim = out.ndim + channel_dim\n",
    "        order = (channel_dim,) + tuple(d for d in range(out.ndim) if d != channel_dim)\n",
    "        out = out.permute(tuple(np.argsort(order)))\n",
    "        out = out.contiguous()\n",
    "\n",
    "    if is_ndarray:\n",
    "        out = out.numpy()\n",
    "    return out\n",
    "\n",
    "\n",
    "# Function for combining one hot encoded classes\n",
    "def collect_mask(\n",
    "        mask: np.ndarray,\n",
    "        index: Sequence[Union[int, Sequence[int], int]],\n",
    "        out_channel_first: bool = True,\n",
    "):\n",
    "    \"\"\"Collect masks by index.\n",
    "\n",
    "    Collated indices will be summed. For example, `index=(1,(3,4))` will return\n",
    "    `np.stack(mask[...,1], mask[...,3]+mask[...,4])`.\n",
    "\n",
    "    TODO: Add support for adding background.\n",
    "\n",
    "    Args:\n",
    "        mask (ndarray): A (...)xC array.\n",
    "        index (Sequence[int]): The index/indices to select in mask.\n",
    "            If sub-indices are collated, they will be summed.\n",
    "        out_channel_first (bool, optional): Reorders dimensions of output mask to Cx(...)\n",
    "    \"\"\"\n",
    "    if isinstance(index, int):\n",
    "        index = (index,)\n",
    "\n",
    "    if not any(isinstance(idx, Sequence) for idx in index):\n",
    "        mask = mask[..., index]\n",
    "    else:\n",
    "        o_seg = []\n",
    "        for idx in index:\n",
    "            c_seg = mask[..., idx]\n",
    "            if isinstance(idx, Sequence):\n",
    "                c_seg = np.sum(c_seg, axis=-1)\n",
    "            o_seg.append(c_seg)\n",
    "        mask = np.stack(o_seg, axis=-1)\n",
    "\n",
    "    if out_channel_first:\n",
    "        last_idx = len(mask.shape) - 1\n",
    "        mask = np.transpose(mask, (last_idx,) + tuple(range(0, last_idx)))\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "# Function for transforming segmentation classes into categorical\n",
    "def one_hot_to_categorical(x, channel_dim: int = 1, background=False):\n",
    "    \"\"\"Converts one-hot encoded predictions to categorical predictions.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor | np.ndarray): One-hot encoded predictions.\n",
    "        channel_dim (int, optional): Channel dimension.\n",
    "            Defaults to ``1`` (i.e. ``(B,C,...)``).\n",
    "        background (bool, optional): If ``True``, assumes index 0 in the\n",
    "            channel dimension is the background.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor | np.ndarray: Categorical array or tensor. If ``background=False``,\n",
    "        the output will be 1-indexed such that ``0`` corresponds to the background.\n",
    "    \"\"\"\n",
    "    is_ndarray = isinstance(x, np.ndarray)\n",
    "    if is_ndarray:\n",
    "        x = torch.as_tensor(x)\n",
    "\n",
    "    if background is not None and background is not False:\n",
    "        out = torch.argmax(x, channel_dim)\n",
    "    else:\n",
    "        out = torch.argmax(x.type(torch.long), dim=channel_dim) + 1\n",
    "        out = torch.where(x.sum(channel_dim) == 0, torch.tensor([0], device=x.device), out)\n",
    "\n",
    "    if is_ndarray:\n",
    "        out = out.numpy()\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T11:57:37.790791Z",
     "end_time": "2024-02-22T11:57:37.803617Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTR_013\n",
      "<KeysViewHDF5 ['kspace', 'maps', 'masks', 'target']>\n",
      "(512, 512, 160, 2, 8) (512, 512, 160, 4) (512, 512, 160, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the corresponding data\n",
    "dataset_dir = '/data/projects/recon/data/public/multitask/skm-tea/v1-release/'\n",
    "meta_dir = Path(dataset_dir) / 'all_metadata.csv'\n",
    "meta_data = pd.read_csv(meta_dir)\n",
    "\n",
    "recon_file = Path(dataset_dir) / \"files_recon_calib-24/\"\n",
    "\n",
    "seg_file = Path(dataset_dir)  / str(\"segmentation_masks/raw-data-track/\")\n",
    "\n",
    "file = json(\"\")\n",
    "patient_id = 'MTR_013' #meta_data['MTR_ID'][60]\n",
    "print(patient_id)\n",
    "meta_data = meta_data[meta_data['MTR_ID']==patient_id]\n",
    "\n",
    "with h5py.File(str(recon_file / patient_id)+'.h5', \"r\") as f:\n",
    "    print(f.keys())\n",
    "    kspace_org = f[\"kspace\"][:, :, :, :, :]  # Shape: (x, ky, kz, #echos, #coils)\n",
    "    maps_org = f[\"maps\"][:, :, :, :, :]      # Shape: (x, ky, kz, #coils, #maps) - maps are the same for both echos\n",
    "    image_org = f['target'][()]\n",
    "\n",
    "segmentation = nib.load(str(seg_file / patient_id)+'.nii.gz').get_fdata()\n",
    "segmentation_one = categorical_to_one_hot(segmentation,channel_dim=-1)\n",
    "segmentation_one_org = collect_mask(segmentation_one, (0, 1, (2, 3), (4, 5)), out_channel_first=False)\n",
    "crop_scale = [1,1,1] #Option to crop\n",
    "print(kspace_org.shape, segmentation_one_org.shape, maps_org.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T11:57:38.249384Z",
     "end_time": "2024-02-22T11:58:00.892590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'categories', 'tissues', 'images', 'annotations'])\n",
      "[{'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 1, 'name': 'Meniscal Tear (Myxoid)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 2, 'name': 'Meniscal Tear (Horizontal)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 3, 'name': 'Meniscal Tear (Radial)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 4, 'name': 'Meniscal Tear (Vertical/Longitudinal)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 5, 'name': 'Meniscal Tear (Oblique)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 6, 'name': 'Meniscal Tear (Complex)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 7, 'name': 'Meniscal Tear (Flap)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 8, 'name': 'Meniscal Tear (Extrusion)'}, {'supercategory': 'Ligament Tear', 'supercategory_id': 2, 'id': 9, 'name': 'Ligament Tear (Low-Grade Sprain)'}, {'supercategory': 'Ligament Tear', 'supercategory_id': 2, 'id': 10, 'name': 'Ligament Tear (Moderate Grade Sprain or Mucoid Degeneration)'}, {'supercategory': 'Ligament Tear', 'supercategory_id': 2, 'id': 11, 'name': 'Ligament Tear (Full Thickness/Complete Tear)'}, {'supercategory': 'Cartilage Lesion', 'supercategory_id': 3, 'id': 12, 'name': 'Cartilage Lesion (1)'}, {'supercategory': 'Cartilage Lesion', 'supercategory_id': 3, 'id': 13, 'name': 'Cartilage Lesion (2A)'}, {'supercategory': 'Cartilage Lesion', 'supercategory_id': 3, 'id': 14, 'name': 'Cartilage Lesion (2B)'}, {'supercategory': 'Cartilage Lesion', 'supercategory_id': 3, 'id': 15, 'name': 'Cartilage Lesion (3)'}, {'supercategory': 'Effusion', 'supercategory_id': 4, 'id': 16, 'name': 'Effusion'}]\n",
      "5    48\n",
      "Name: PatientID, dtype: int64\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T11:58:00.892272Z",
     "end_time": "2024-02-22T11:58:00.893334Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([243.0, 238.0, 77.0, 48.0, 30.0, 8.0], 9)]\n",
      "[([249.0, 258.0, 80.0, 7.0, 6.0, 4.0], 9), ([195.0, 36.0, 54.0, 25.0, 6.0, 6.0], 16), ([187.0, 109.0, 62.0, 6.0, 3.0, 8.0], 13)]\n",
      "[]\n",
      "[([226.0, 132.0, 54.0, 95.0, 180.0, 42.0], 16), ([213.0, 259.0, 59.0, 76.0, 41.0, 30.0], 11)]\n",
      "[([230.0, 142.0, 68.0, 79.0, 62.0, 39.0], 13)]\n",
      "[([151.0, 95.0, 55.0, 177.0, 132.0, 70.0], 16)]\n",
      "[([171.0, 117.0, 46.0, 73.0, 27.0, 26.0], 12), ([12.0, 108.0, 35.0, 264.0, 69.0, 77.0], 16)]\n",
      "[]\n",
      "[]\n",
      "[([113.0, 125.0, 44.0, 85.0, 19.0, 25.0], 16), ([225.0, 165.0, 79.0, 17.0, 11.0, 11.0], 13)]\n",
      "[([231.0, 136.0, 67.0, 46.0, 26.0, 27.0], 13), ([44.0, 133.0, 19.0, 153.0, 93.0, 59.0], 16), ([266.0, 176.0, 57.0, 31.0, 98.0, 49.0], 8)]\n",
      "[]\n",
      "[([276.0, 278.0, 50.0, 5.0, 7.0, 11.0], 5), ([250.0, 122.0, 52.0, 32.0, 40.0, 19.0], 14)]\n",
      "[([257.0, 236.0, 20.0, 16.0, 71.0, 20.0], 2), ([255.0, 313.0, 25.0, 65.0, 38.0, 40.0], 4), ([108.0, 144.0, 40.0, 49.0, 20.0, 33.0], 12), ([79.0, 140.0, 80.0, 188.0, 98.0, 55.0], 16)]\n",
      "[([155.0, 126.0, 70.0, 17.0, 24.0, 17.0], 12)]\n",
      "[([278.0, 302.0, 26.0, 34.0, 56.0, 21.0], 6), ([293.0, 242.0, 26.0, 19.0, 75.0, 21.0], 14), ([310.0, 226.0, 28.0, 7.0, 66.0, 16.0], 13), ([119.0, 95.0, 61.0, 118.0, 44.0, 56.0], 14), ([219.0, 126.0, 58.0, 68.0, 61.0, 19.0], 14), ([12.0, 108.0, 53.0, 233.0, 137.0, 72.0], 16)]\n",
      "[([316.0, 287.0, 41.0, 19.0, 49.0, 34.0], 6), ([312.0, 244.0, 53.0, 18.0, 76.0, 17.0], 12), ([181.0, 132.0, 73.0, 80.0, 26.0, 44.0], 16)]\n",
      "[([33.0, 124.0, 30.0, 217.0, 103.0, 103.0], 16), ([243.0, 186.0, 36.0, 34.0, 114.0, 48.0], 8), ([122.0, 279.0, 28.0, 114.0, -68.0, 38.0], 14)]\n",
      "[([201.0, 141.0, 46.0, 52.0, 18.0, 28.0], 12), ([316.0, 199.0, 45.0, 15.0, 55.0, 17.0], 13)]\n",
      "[]\n",
      "[]\n",
      "[([138.0, 130.0, 77.0, 208.0, 97.0, 53.0], 16), ([114.0, 123.0, 23.0, 208.0, 102.0, 49.0], 16), ([345.0, 320.0, 38.0, 9.0, 9.0, 13.0], 2)]\n",
      "[]\n",
      "[([273.0, 115.0, 37.0, 35.0, 29.0, 39.0], 12), ([128.0, 106.0, 27.0, 218.0, 149.0, 66.0], 16)]\n",
      "[([260.0, 139.0, 42.0, 37.0, 10.0, 7.0], 13), ([222.0, 130.0, 43.0, 66.0, 30.0, 30.0], 13)]\n",
      "[([10.0, 126.0, 35.0, 197.0, 132.0, 112.0], 16), ([129.0, 318.0, 10.0, 248.0, 112.0, 56.0], 16), ([218.0, 125.0, 51.0, 88.0, 142.0, 61.0], 16), ([281.0, 291.0, 42.0, 11.0, 7.0, 7.0], 6), ([274.0, 185.0, 45.0, 25.0, 90.0, 34.0], 8)]\n",
      "[([275.0, 276.0, 40.0, 19.0, 37.0, 26.0], 2)]\n",
      "[([69.0, 156.0, 34.0, 191.0, 38.0, 30.0], 16)]\n",
      "[([299.0, 244.0, 72.0, 84.0, 78.0, 22.0], 9), ([276.0, 116.0, 59.0, 59.0, 35.0, 49.0], 12), ([186.0, 117.0, 49.0, 163.0, 50.0, 58.0], 16)]\n",
      "[]\n",
      "[([330.0, 232.0, 54.0, 5.0, 19.0, 10.0], 3), ([227.0, 156.0, 55.0, 20.0, 12.0, 13.0], 12)]\n",
      "[([45.0, 109.0, 30.0, 264.0, 121.0, 107.0], 16), ([322.0, 216.0, 42.0, 4.0, 11.0, 8.0], 2), ([307.0, 198.0, 50.0, 24.0, 39.0, 30.0], 15), ([210.0, 144.0, 44.0, 102.0, 54.0, 49.0], 15), ([309.0, 254.0, 37.0, 15.0, -5.0, 31.0], 15)]\n",
      "[([197.0, 200.0, 62.0, 85.0, 95.0, 12.0], 10), ([235.0, 155.0, 73.0, 21.0, 17.0, 10.0], 13), ([258.0, 189.0, 19.0, 34.0, 90.0, 19.0], 16), ([256.0, 162.0, 78.0, 39.0, 90.0, 27.0], 16)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[([287.0, 241.0, 74.0, 51.0, 51.0, 16.0], 11), ([296.0, 269.0, 75.0, 34.0, 56.0, 17.0], 9)]\n",
      "[([211.0, 117.0, 64.0, 67.0, 28.0, 33.0], 12)]\n",
      "[([299.0, 246.0, 46.0, 17.0, 50.0, 26.0], 2), ([46.0, 109.0, 50.0, 259.0, 165.0, 82.0], 16)]\n",
      "[([196.0, 115.0, 49.0, 46.0, 43.0, 28.0], 12), ([289.0, 165.0, 74.0, 25.0, 37.0, 14.0], 13)]\n",
      "[([241.0, 238.0, 78.0, 25.0, 26.0, 12.0], 11), ([210.0, 147.0, 75.0, 29.0, 10.0, 13.0], 14)]\n",
      "[]\n",
      "[]\n",
      "[([260.0, 270.0, 45.0, 53.0, 73.0, 30.0], 6), ([307.0, 189.0, 44.0, 34.0, 57.0, 38.0], 8), ([299.0, 222.0, 43.0, 20.0, 85.0, 20.0], 15), ([279.0, 173.0, 45.0, 35.0, 143.0, 32.0], 15), ([172.0, 124.0, 73.0, 75.0, 28.0, 39.0], 15), ([225.0, 145.0, 70.0, 51.0, 31.0, 12.0], 14), ([81.0, 41.0, 43.0, 211.0, 172.0, 87.0], 16)]\n",
      "[([107.0, 145.0, 44.0, 83.0, 26.0, 31.0], 16)]\n",
      "[([367.0, 207.0, 74.0, -4.0, 96.0, 197.0], 9), ([195.0, 100.0, 66.0, 70.0, 39.0, 43.0], 13), ([308.0, 151.0, 70.0, 31.0, 25.0, 23.0], 13)]\n",
      "[([271.0, 192.0, 27.0, 37.0, 80.0, 38.0], 6), ([245.0, 280.0, 22.0, 25.0, 54.0, 16.0], 8), ([177.0, 171.0, 76.0, 120.0, 148.0, 48.0], 13), ([130.0, 128.0, 24.0, 105.0, 54.0, 39.0], 15), ([8.0, 99.0, 19.0, 251.0, 253.0, 85.0], 16)]\n",
      "[([145.0, 118.0, 58.0, 122.0, 47.0, 38.0], 16)]\n",
      "[([127.0, 119.0, 18.0, 130.0, 117.0, 25.0], 16), ([230.0, 240.0, 69.0, 8.0, 22.0, 14.0], 10), ([217.0, 140.0, 79.0, 82.0, 96.0, 47.0], 14), ([182.0, 306.0, 41.0, 61.0, 19.0, 19.0], 14), ([310.0, 305.0, 40.0, 13.0, 27.0, 23.0], 14)]\n",
      "[([324.0, 315.0, 47.0, 6.0, 9.0, 8.0], 2)]\n",
      "[([211.0, 134.0, 66.0, 84.0, 30.0, 52.0], 14), ([164.0, 118.0, 75.0, 88.0, 28.0, 45.0], 13), ([308.0, 163.0, 36.0, 45.0, 78.0, 25.0], 13), ([125.0, 91.0, 35.0, 222.0, 153.0, 74.0], 16)]\n",
      "[([39.0, 80.0, 17.0, 204.0, 106.0, 108.0], 16)]\n",
      "[([85.0, 120.0, 38.0, 128.0, 32.0, 57.0], 16), ([158.0, 128.0, 73.0, 30.0, 8.0, 9.0], 12)]\n",
      "[([322.0, 214.0, 47.0, 22.0, 73.0, 23.0], 12), ([331.0, 214.0, 54.0, 20.0, 92.0, 19.0], 12), ([177.0, 120.0, 78.0, 81.0, 35.0, 42.0], 13)]\n",
      "[([211.0, 112.0, 50.0, 80.0, 33.0, 36.0], 12), ([370.0, 294.0, 40.0, 35.0, 66.0, 25.0], 12)]\n",
      "[([282.0, 199.0, 50.0, 20.0, 39.0, 23.0], 13)]\n",
      "[([262.0, 158.0, 42.0, 96.0, 73.0, 21.0], 16)]\n",
      "[]\n",
      "[]\n",
      "[([120.0, 93.0, 73.0, 196.0, 115.0, 53.0], 16), ([144.0, 133.0, 36.0, 49.0, 18.0, 27.0], 16), ([69.0, 169.0, 6.0, 214.0, 115.0, 20.0], 16)]\n",
      "[([41.0, 114.0, 17.0, 265.0, 126.0, 45.0], 16), ([355.0, 160.0, 31.0, 28.0, 24.0, 31.0], 16), ([327.0, 168.0, 31.0, 23.0, 184.0, 42.0], 6), ([341.0, 241.0, 25.0, 12.0, 63.0, 37.0], 8), ([348.0, 229.0, 29.0, 12.0, 75.0, 37.0], 14)]\n",
      "[]\n",
      "[([296.0, 283.0, 32.0, 26.0, 44.0, 36.0], 6), ([303.0, 162.0, 34.0, 28.0, 85.0, 31.0], 8), ([203.0, 214.0, 73.0, 110.0, 110.0, 20.0], 10), ([166.0, 102.0, 66.0, 43.0, 39.0, 45.0], 12), ([317.0, 218.0, 35.0, 15.0, 117.0, 34.0], 13), ([285.0, 160.0, 37.0, 37.0, 94.0, 38.0], 14), ([182.0, 121.0, 60.0, 96.0, 39.0, 39.0], 14)]\n",
      "[([199.0, 143.0, 72.0, 54.0, 31.0, 22.0], 13)]\n",
      "[]\n",
      "[]\n",
      "[([144.0, 98.0, 44.0, 153.0, 87.0, 71.0], 16)]\n",
      "[([249.0, 221.0, 52.0, 48.0, 94.0, 59.0], 16), ([166.0, 147.0, 75.0, 44.0, 30.0, 31.0], 16)]\n",
      "[([108.0, 84.0, 38.0, 135.0, 34.0, 33.0], 16), ([328.0, 157.0, 35.0, 42.0, 84.0, 66.0], 16)]\n",
      "[([87.0, 108.0, 19.0, 168.0, 141.0, 43.0], 16), ([187.0, 150.0, 67.0, 27.0, 11.0, 14.0], 14), ([248.0, 186.0, 68.0, 14.0, 22.0, 14.0], 14)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[([184.0, 257.0, 75.0, 51.0, 33.0, 13.0], 10)]\n",
      "[]\n",
      "[([254.0, 114.0, 66.0, 119.0, 90.0, 69.0], 16)]\n",
      "[([271.0, 147.0, 31.0, 55.0, 177.0, 25.0], 4), ([300.0, 134.0, 30.0, 47.0, 61.0, 53.0], 8), ([195.0, 215.0, 53.0, 119.0, 115.0, 37.0], 10), ([90.0, 94.0, 79.0, 100.0, 38.0, 17.0], 13), ([295.0, 190.0, 32.0, 25.0, 63.0, 27.0], 13), ([58.0, 68.0, 16.0, 261.0, 124.0, 78.0], 16)]\n",
      "[([310.0, 174.0, 74.0, 19.0, 17.0, 21.0], 12)]\n",
      "[([197.0, 160.0, 66.0, 57.0, 24.0, 39.0], 13)]\n",
      "[([125.0, 118.0, 59.0, 84.0, 40.0, 52.0], 12)]\n",
      "[([28.0, 126.0, 40.0, 213.0, 91.0, 67.0], 16), ([191.0, 140.0, 80.0, 22.0, 7.0, 15.0], 13)]\n",
      "[([294.0, 313.0, 19.0, 51.0, 47.0, 47.0], 6), ([221.0, 221.0, 64.0, 106.0, 121.0, 30.0], 11), ([301.0, 182.0, 22.0, 31.0, 162.0, 25.0], 14), ([138.0, 125.0, 32.0, 91.0, 23.0, 44.0], 13), ([178.0, 132.0, 30.0, 149.0, 102.0, 43.0], 14)]\n",
      "[([303.0, 273.0, 42.0, 17.0, 48.0, 20.0], 2)]\n",
      "dict_keys(['info', 'categories', 'tissues', 'images', 'annotations'])\n",
      "[{'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 1, 'name': 'Meniscal Tear (Myxoid)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 2, 'name': 'Meniscal Tear (Horizontal)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 3, 'name': 'Meniscal Tear (Radial)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 4, 'name': 'Meniscal Tear (Vertical/Longitudinal)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 5, 'name': 'Meniscal Tear (Oblique)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 6, 'name': 'Meniscal Tear (Complex)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 7, 'name': 'Meniscal Tear (Flap)'}, {'supercategory': 'Meniscal Tear', 'supercategory_id': 1, 'id': 8, 'name': 'Meniscal Tear (Extrusion)'}, {'supercategory': 'Ligament Tear', 'supercategory_id': 2, 'id': 9, 'name': 'Ligament Tear (Low-Grade Sprain)'}, {'supercategory': 'Ligament Tear', 'supercategory_id': 2, 'id': 10, 'name': 'Ligament Tear (Moderate Grade Sprain or Mucoid Degeneration)'}, {'supercategory': 'Ligament Tear', 'supercategory_id': 2, 'id': 11, 'name': 'Ligament Tear (Full Thickness/Complete Tear)'}, {'supercategory': 'Cartilage Lesion', 'supercategory_id': 3, 'id': 12, 'name': 'Cartilage Lesion (1)'}, {'supercategory': 'Cartilage Lesion', 'supercategory_id': 3, 'id': 13, 'name': 'Cartilage Lesion (2A)'}, {'supercategory': 'Cartilage Lesion', 'supercategory_id': 3, 'id': 14, 'name': 'Cartilage Lesion (2B)'}, {'supercategory': 'Cartilage Lesion', 'supercategory_id': 3, 'id': 15, 'name': 'Cartilage Lesion (3)'}, {'supercategory': 'Effusion', 'supercategory_id': 4, 'id': 16, 'name': 'Effusion'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "annotation_set =\"/data/projects/recon/data/public/multitask/skm-tea/v1-release/annotations/v1.0.0/train.json\"\n",
    "with open(annotation_set, \"r\", encoding=\"utf-8\") as f:\n",
    "    annotation_set = json.load(f)\n",
    "    slice = 80\n",
    "for image in annotation_set[\"images\"]:\n",
    "    image_id = image['scan_id']\n",
    "    annotations = [annotation for annotation in annotation_set['annotations'] if annotation['image_id'] == image['id']]\n",
    "    bbox_class = [(annotation['bbox'],annotation['category_id']) for annotation in annotations\n",
    "                  if slice in range(int(annotation['bbox'][2]),int(annotation['bbox'][0]+annotation['bbox'][5]),1)]\n",
    "    print(bbox_class)\n",
    "print(annotation_set.keys())\n",
    "print(annotation_set['categories'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T14:50:37.827329Z",
     "end_time": "2024-02-27T14:50:37.830885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tmpaquaij/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2024-1-22 Python-3.10.13 torch-2.0.1+cu117 CUDA:0 (Tesla V100-PCIE-32GB, 32501MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 262)\n"
     ]
    },
    {
     "data": {
      "text/plain": "          xmin       ymin        xmax       ymax  confidence  class  \\\n0    11.462501   1.912500   11.462501   1.912500         1.0      9   \n1    14.736087   1.912500   14.736503   1.912500         1.0     32   \n2    21.287500   1.912500   21.287500   1.912500         1.0      9   \n3    19.768314   1.912500   35.906689   1.912500         1.0     32   \n4    55.675095   1.912500   72.049911   1.912500         1.0     74   \n..         ...        ...         ...        ...         ...    ...   \n995  81.875000  13.375001   81.875000  13.375001         1.0     60   \n996  63.876850  13.375001  112.972939  13.375001         1.0     60   \n997  70.412498   0.000000  119.537506  51.119919         1.0     60   \n998  76.962502  13.066896  126.087502  13.683105         1.0     57   \n999  83.512512  13.375001  132.637497  13.375001         1.0     57   \n\n              name  \n0    traffic light  \n1      sports ball  \n2    traffic light  \n3      sports ball  \n4            clock  \n..             ...  \n995   dining table  \n996   dining table  \n997   dining table  \n998          couch  \n999          couch  \n\n[1000 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n      <th>confidence</th>\n      <th>class</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.462501</td>\n      <td>1.912500</td>\n      <td>11.462501</td>\n      <td>1.912500</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>traffic light</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14.736087</td>\n      <td>1.912500</td>\n      <td>14.736503</td>\n      <td>1.912500</td>\n      <td>1.0</td>\n      <td>32</td>\n      <td>sports ball</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.287500</td>\n      <td>1.912500</td>\n      <td>21.287500</td>\n      <td>1.912500</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>traffic light</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19.768314</td>\n      <td>1.912500</td>\n      <td>35.906689</td>\n      <td>1.912500</td>\n      <td>1.0</td>\n      <td>32</td>\n      <td>sports ball</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55.675095</td>\n      <td>1.912500</td>\n      <td>72.049911</td>\n      <td>1.912500</td>\n      <td>1.0</td>\n      <td>74</td>\n      <td>clock</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>81.875000</td>\n      <td>13.375001</td>\n      <td>81.875000</td>\n      <td>13.375001</td>\n      <td>1.0</td>\n      <td>60</td>\n      <td>dining table</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>63.876850</td>\n      <td>13.375001</td>\n      <td>112.972939</td>\n      <td>13.375001</td>\n      <td>1.0</td>\n      <td>60</td>\n      <td>dining table</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>70.412498</td>\n      <td>0.000000</td>\n      <td>119.537506</td>\n      <td>51.119919</td>\n      <td>1.0</td>\n      <td>60</td>\n      <td>dining table</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>76.962502</td>\n      <td>13.066896</td>\n      <td>126.087502</td>\n      <td>13.683105</td>\n      <td>1.0</td>\n      <td>57</td>\n      <td>couch</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>83.512512</td>\n      <td>13.375001</td>\n      <td>132.637497</td>\n      <td>13.375001</td>\n      <td>1.0</td>\n      <td>57</td>\n      <td>couch</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom',path = 'yolov5s.pt')\n",
    "print(np.abs(image_org[128:-128,125:-125,80,0,0]).shape)\n",
    "pred = model(np.abs(image_org[128:-128,125:-125,80,0,0]))\n",
    "pred.pandas().xyxy[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T14:47:15.722224Z",
     "end_time": "2024-02-22T14:47:17.109973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DetectionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (12): Concat()\n",
      "    (13): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (16): Concat()\n",
      "    (17): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (19): Concat()\n",
      "    (20): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (22): Concat()\n",
      "    (23): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (24): Detect(\n",
      "      (m): ModuleList(\n",
      "        (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T11:59:26.115901Z",
     "end_time": "2024-02-22T11:59:26.157078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
