# coding=utf-8

# Generated by CodiumAI
import os
import pytest
import torch
from omegaconf import DictConfig
from pytorch_lightning import Trainer

from atommic.collections.reconstruction.nn.base import BaseMRIModel, BaseSensitivityModel, DistributedMetricSum


class TestDistributedMetricSum:
    # Tests that the initial value of the metric is 0.0 when no initial value is provided
    def test_default_initial_value(self):
        metric = DistributedMetricSum()
        assert metric.compute() == torch.tensor(0.0)

    # Tests that the initial value of the metric is set to the provided custom initial value
    def test_custom_initial_value(self):
        initial_value = torch.tensor(5.0)
        metric = DistributedMetricSum()
        metric.quantity = initial_value
        assert metric.compute() == initial_value

    # Tests that the update method correctly adds the tensor argument to the metric quantity
    def test_update_method_with_tensor_argument(self):
        metric = DistributedMetricSum()
        tensor = torch.tensor(2.0)
        metric.update(tensor)
        assert metric.compute() == tensor

    # Tests that the compute method returns the initial value of the metric when called without calling the update
    # method
    def test_compute_method_without_calling_update(self):
        metric = DistributedMetricSum()
        assert metric.compute() == torch.tensor(0.0)

    # Tests that the compute method returns the correct sum of all tensor values passed to the update method
    def test_compute_method_after_multiple_update_calls(self):
        metric = DistributedMetricSum()
        tensor1 = torch.tensor(2.0)
        tensor2 = torch.tensor(3.0)
        metric.update(tensor1)
        metric.update(tensor2)
        assert metric.compute() == tensor1 + tensor2

    # Tests that the metric state is synchronized across processes when dist_sync_on_step is True
    def test_dist_sync_on_step(self):
        metric = DistributedMetricSum(dist_sync_on_step=True)
        tensor = torch.tensor(2.0)
        metric.update(tensor)
        assert metric.compute() == tensor


class TestBaseMRIModel:
    # Tests that the BaseMRIModel can be initialized with a configuration and trainer objects.
    def test_initialize_with_configuration_and_trainer(self):
        cfg = DictConfig({})
        trainer = Trainer()
        model = BaseMRIModel(cfg, trainer)
        assert isinstance(model, BaseMRIModel)
        assert model.trainer == trainer

    # Tests that the training_step method raises a NotImplementedError.
    def test_training_step_not_implemented(self):
        model = BaseMRIModel(DictConfig({}))
        with pytest.raises(NotImplementedError):
            model.training_step({}, 0)

    # Tests that the validation_step method raises a NotImplementedError.
    def test_validation_step_not_implemented(self):
        model = BaseMRIModel(DictConfig({}))
        with pytest.raises(NotImplementedError):
            model.validation_step({}, 0)

    # Tests that the test_step method raises a NotImplementedError.
    def test_test_step_not_implemented(self):
        model = BaseMRIModel(DictConfig({}))
        with pytest.raises(NotImplementedError):
            model.test_step({}, 0)


class TestBaseSensitivityModel:
    """Tests for the BaseSensitivityModel class."""

    # Tests that the model can be instantiated with default parameters.
    def test_instantiation_with_default_parameters(self):
        model = BaseSensitivityModel()
        assert isinstance(model, BaseSensitivityModel)

    # Tests that the forward method can be called with valid input.
    def test_forward_method_with_valid_input(self):
        model = BaseSensitivityModel()
        masked_kspace = torch.randn([1, 8, 320, 320, 2], dtype=torch.float32)
        mask = torch.randn([1, 1, 320, 320, 1], dtype=torch.float32)
        result = model.forward(masked_kspace, mask, torch.ones_like(masked_kspace))
        assert isinstance(result, torch.Tensor)

    # Tests that the output of the forward method has the expected shape.
    def test_output_shape_of_forward_method(self):
        model = BaseSensitivityModel()
        masked_kspace = torch.randn([1, 8, 320, 320, 2], dtype=torch.float32)
        mask = torch.randn([1, 1, 320, 320, 1], dtype=torch.float32)
        result = model.forward(masked_kspace, mask, torch.ones_like(masked_kspace))
        assert result.shape == (1, 8, 320, 320, 2)

    # Tests that the model can be trained on a small dataset.
    def test_training_on_small_dataset(self):
        model = BaseSensitivityModel()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = torch.nn.MSELoss()
        dataset = torch.randn([10, 8, 320, 320, 2], dtype=torch.float32)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=2)
        for data in dataloader:
            optimizer.zero_grad()
            masked_kspace = data[:, :, :, :, :2]
            mask = torch.randn([2, 1, 320, 320, 1], dtype=torch.float32)
            outputs = model.forward(masked_kspace, mask, torch.ones_like(masked_kspace))
            loss = criterion(outputs, data)
            loss.backward()
            optimizer.step()
        assert True

    # Tests that the model can be saved and loaded successfully.
    def test_saving_and_loading_model(self):
        model = BaseSensitivityModel()
        torch.save(model.state_dict(), "model.pth")
        loaded_model = BaseSensitivityModel()
        loaded_model.load_state_dict(torch.load("model.pth"))
        assert isinstance(loaded_model, BaseSensitivityModel)
        os.remove("model.pth")
